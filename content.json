[{"title":"Hexo搭建GitPage静态博客","date":"2018-01-21T13:00:00.000Z","path":"2018/01/21/linux/hexo_on_gitpage/","text":"作者： 耗子007 环境准备 docker nodejs镜像 hexo git相关 docker安装docker的安装请参考官方文档：https://docs.docker.com/engine/installation/ nodejs镜像国内可以使用Docker官方的加速地址，具体配置参考官方文档： https://www.docker-cn.com/registry-mirror 本文使用修改config的方式： 123&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 然后下载nodejs的官方镜像： 1docker pull node 安装hexo首先启动一个node的容器 12docker run -it -p 4000:4000 node /bin/bash# 映射容器的4000端口到host的4000端口，是为了方便测试hexo生成的静态网站是否正常 然后，安装hexo 1npm install -g hexo-cli 创建git仓库gitpage对仓库的要求就是仓库名的格式必须为：username.github.io，例如本文仓库名：duguhaotian.github.io 配置git公钥首先，在容器中生成公钥 1ssh-keygen 然后拷贝公钥到你Git上，具体步骤百度。 1cat ~/.ssh/id_rsa.pub 配置git配置用户名和邮箱 12git config --global user.name xxxxgit config --global user.email xxxx@xxx.com 构建hexo工程创建工程目录，然后通过hexo初始化目录 12mkdir testhexo init test 生成的目录结构如下： 1234567891011~/test# tree -L 1.|-- _config.yml|-- db.json|-- node_modules|-- package-lock.json|-- package.json|-- public|-- scaffolds|-- source|-- themes 增加博客的方式有两种： 通过hexo生成新的博客文件，然后写博客 或者把写好的博客文件（markdown格式），放入test/source/_posts/目录 安装依赖库由于hexo依赖一些库，如支持推送静态页面到git的库等。最好安装下面所有库 1234567891011121314npm installnpm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --save 生成静态网站在test目录执行： 1234# 生成静态页面hexo g # 部署本地静态网站(localhost:4000)hexo s 查看本地静态网站是否构建正常，如果无问题，直接推送到github仓库。 推送到GitPage当本地网站验证无误，就可以推送到你的Git仓库了，然后Github会自动部署你的GitPage 首先，修改hexo的配置文件：_config.yml ，增加deploy的配置 1234deploy: type: git repository: https://github.com/duguhaotian/duguhaotian.github.io.git branch: master 配置文件默认情况如下： 12deploy: type: 因此，我们增加type和对应的repository地址，还有git分支。 最后，直接利用hexo的deploy功能把hexo生成的静态页面推送到Github上我们新建的仓库。 123hexo d# 或者hexo g -d 跟换皮肤首先，在hexo官网找到自己需要的皮肤：https://hexo.io/themes/例如，material的皮肤，然后获取git地址：https://github.com/viosey/hexo-theme-material 主要步骤： 把该目录拷贝到themes/下面 重命名为material 修改test/_config.yml配置文件中theme为：material 把test/theme/material/_config.template.yml拷贝一份为:test/themes/material/_config.yaml，不然hexo生成静态页面会错误 更多配置可以参考下面的手册：https://material.viosey.com/docs/#/ 参考文章 https://hexo.io/docs/ https://www.jianshu.com/p/15ae47eddc56 https://www.docker-cn.com/registry-mirror https://docs.docker.com/ https://material.viosey.com/docs/#/","tags":[]},{"title":"perl的locale异常","date":"2018-01-21T12:28:36.000Z","path":"2018/01/21/linux/bugfix/perl_locale_error/","text":"作者： 耗子007 问题1234perl: warning: Falling back to the standard locale (\"C\").perl: warning: Setting locale failed.sh: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)sh: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8) 解决方法1234locale-gen en_US en_US.UTF-8dpkg-reconfigure localeslocaleexport LC_ALL=en_US.UTF-8","tags":[]},{"title":"电子书制作记录","date":"2018-01-21T12:27:18.000Z","path":"2018/01/21/linux/get_ebook_spard/","text":"作者： 耗子007 博客：http://abirdcfly.github.io/2016/03/07/calibre2mobi/","tags":[]},{"title":"IP命令使用","date":"2018-01-08T10:50:50.000Z","path":"2018/01/08/linux/tools/ip_command/","text":"作者： 耗子007 up/down veth接口Usage: ip link set dev &lt;interface&gt; up ip link set dev &lt;interface&gt; downExample: ip link set dev eth0 up ip link set dev eth0 down创建veth对Usage: ip link add &lt;interface nameA&gt; type veth peer name &lt;interface nameB&gt;Example: ip link add veth0 type veth peer name veth1设置veth网络命名空间Usage: ip link set &lt;interface&gt; netns &lt;netnamespace&gt;Example: ip netns add hello_test //创建一个名为hell_test的netns（网络命名空间） ip link set veth1 netns hello_test重命名veth接口Usage: ip link set vethA name vethBExample: ip link set vethA down ip link set vethA name vethB ip link set vethB up","tags":[]},{"title":"Git用法","date":"2018-01-07T10:50:55.000Z","path":"2018/01/07/linux/tools/git_usages/","text":"作者： 耗子007 Git用法汇总Git命令自动补全123source /etc/bash_completion.d/git# orsource /usr/share/bash-completion/completions/git 可以添加到~/.bashrc","tags":[]},{"title":"技术汇集","date":"2018-01-01T01:01:01.000Z","path":"2018/01/01/linux/knowledge_topology/","text":"作者： 耗子007 C语言c语言测试套框架：https://libcheck.github.io/check/","tags":[]},{"title":"pip命令初识","date":"2017-12-12T12:01:22.000Z","path":"2017/12/12/python/pip_command/","text":"作者： 耗子007 基础用法1. 安装指定版本的包1pip3 install docker-py==1.8.1 2. 使用代理proxy1pip3 --proxy=http://username:password@proxy.com:8080 install docker-py==1.8.1","tags":[]},{"title":"nginx问题跟踪","date":"2017-08-08T10:05:47.000Z","path":"2017/08/08/linux/tools/nginx_related/","text":"作者： 耗子007 问题描述访问nginx搭建的网站时，报403 forbidden错误的原因。 解决办法第一，是因为缺少index.html或者index.php等第二，是因为没有权限。 参考：http://blog.51yip.com/apachenginx/1512.html","tags":[]},{"title":"watchdog分析","date":"2017-06-02T16:19:29.000Z","path":"2017/06/02/linux/kernel/linux_scheduling_softlockup&hardlockup/","text":"作者： 耗子007 softlockup和hardlockup含义softlockup内核在内核模式loop超过get_softlockup_thresh()获取的阈值时间，导致其他任务没有机会运行的bug，称为”softlockup”。简单来说，就是抢占被关闭时间超过阈值，导致其他进程无法调度。 hardlockupCPU在内核模式loop时间超过hw_nmi_get_sample_period函数获取的阈值时间，导致其他中断不能运行的bug，称为”hardlockup”。简单来说，就是中断被关闭时间超过阈值，导致其他中断无法运行。 softlockup注册和触发流程基于proc文件系统的watchdog流程1234567proc_watchdog_update 更新watchdog状态，如果开启了watchdog，触发开狗流程 --&gt; watchdog_enable_all_cpus 打开所有cpu的狗 --&gt; smpboot_register_percpu_thread(&amp;watchdog_threads) 创建启动所有CPU上面的hotplug相关线程 --&gt; __smpboot_create_thread 创建线程，线程执行的函数是smpboot_thread_fn --&gt; smpboot_thread_fn 开始会注册调用watchdog_threads的setup（就是watchdog_enable），正常流程会不断的执行watchdog_threads的thread_fn --&gt; watchdog_enabled 会启动一个hrtimer的定时器，触发的回调函数是watchdog_timer_fn --&gt; watchdog_timer_fn 根据is_softlockup判断是否发生softlockup watchdog函数就是喂狗，保证不出现softlockup，这里不需要关注太详细。 123456789static void watchdog(unsigned int cpu)&#123; __this_cpu_write(soft_lockup_hrtimer_cnt, __this_cpu_read(hrtimer_interrupts)); __touch_watchdog(); if (!(watchdog_enabled &amp; NMI_WATCHDOG_ENABLED)) watchdog_nmi_disable(cpu);&#125; 内核初始化时的流程tick的方式，注册watchdog。 12345678kernel_init 内核初始化 --&gt; kernel_init_freeable --&gt; lockup_detector_init 如果开狗了会执行watchdog_enable_all_cpus；如果开启了CONFIG_TICKLESS，会注册tick_notify。 --&gt; watchdog_enable_all_cpus 后续流程和proc的一致，参考上面的分析 --&gt; register_tick_notifier 注册回调函数softlockup_tickonoff_callback --&gt; softlockup_tickonoff_callback 注册回调函数softlockup_tick_onoff --&gt; softlockup_tick_onoff 如果tick是打开的，会启动一个hrtimer，定期执行watchdog_timer_fn函数 --&gt; watchdog_timer_fn 和上面的流程一致了","tags":[]},{"title":"legacy_va_layout设置大堆","date":"2017-06-02T16:19:29.000Z","path":"2017/06/02/linux/kernel/linux_kernel_bigheap/","text":"作者： 耗子007 设置/proc/sys/vm/legacy_va_layout为0，调整进程地址空间的heap增长方向为从上往下。这样可以使得heap的上限超过2G。 120 ----------------------------------------------------------------------------------------- 3G -------- 4G保留 | 代码段 | 数据段 | BSS段 | 堆-增长方向向上 | 内存映射 | 栈-增长方向向下 | 命令行参数 | 环境变量 内核段 1234/proc/sys/vm/legacy_va_layout (since Linux 2.6.9) If nonzero, this disables the new 32-bit memory-mapping layout; the kernel will use the legacy (2.4) layout for all processes. 修改heap增长方向代码（以linux4.1的arm为例） 123456789101112131415void arch_pick_mmap_layout(struct mm_struct *mm)&#123; unsigned long random_factor = 0UL; if (current-&gt;flags &amp; PF_RANDOMIZE) random_factor = arch_mmap_rnd(); if (mmap_is_legacy()) &#123; //获取legacy_va_layout的值，非零使用正常模式 mm-&gt;mmap_base = TASK_UNMAPPED_BASE + random_factor; mm-&gt;get_unmapped_area = arch_get_unmapped_area; &#125; else &#123; //为零，使用自上向下的模式 mm-&gt;mmap_base = mmap_base(random_factor); mm-&gt;get_unmapped_area = arch_get_unmapped_area_topdown; &#125;&#125;","tags":[]},{"title":"ip操作docker容器命名空间","date":"2017-05-08T19:29:26.000Z","path":"2017/05/08/docker/ip_manipulate_docker_netns/","text":"作者： 耗子007 基本操作在host上，操作容器的网络设备 需要查到容器的进程id==cpid，可以通过 1cpid=$(docker inspect --format &apos;&#123;&#123;.State.Pid&#125;&#125;&apos; $1) 需要把容器的netns挂到ip命令能操作的netns中—– 1ln -s &quot;/proc/$cpid/ns/net&quot; &quot;/var/run/netns/$cpid&quot; 查看容器中所有的网络设备以及配置信息 1ip netns exec $cpid ip a 查看容器中网络设备的类型信息： 1ip netns exec $cpid ethtool &quot;driver name（如eth0）&quot;","tags":[]},{"title":"sqlite数据库修改失败","date":"2017-05-07T22:32:21.000Z","path":"2017/05/07/linux/bugfix/sqlite_can_not_write_error/","text":"作者： 耗子007 现象用sqlite data browser 执行update命令，报错误： 1unable to open database file 解决方法sqlite库在对数据库进行操作时（本人估计是写操作），会在数据库的当前文件夹下创建一个临时文件，当操作结束时，该临时文件将被删除。 而远程用户一般不具备有对临时文件足够的权限,所以会造成 无法打开、写或者删除临时文件。解决的方法就是递归地（加-R）将数据库所在文件夹设置为任何用户都有可读可写可删的权限。假如sqlite数据库路径为/database/， 则： 1chmod -R 755 /database/ 参考文章：http://blog.csdn.net/benthy2/article/details/17901821","tags":[]},{"title":"基于docker容器的wordpress迁移","date":"2017-05-07T22:31:33.000Z","path":"2017/05/07/docker/docker_wordpress_migrate/","text":"作者： 耗子007 前提我的wordpress是用sqlite作为数据库的wordpress是运行在docker容器里面的网站的所有数据都有备份安装docker按照“基于centos搭建wordpress的docker镜像”制作对应的docker镜像（假设名字为wordpress_sqlite）拷贝备份数据到新机器的/workspace/wordpress/blogs/，执行 1docker run –privileged -itd -p 8080:80 -v /workspace/wordpress/blogs/:/var/www/html wordpress_sqlite bash -l -c “/sbin/init” 此时，网站应该可以正常运行了。 注意：如果你修改了网站的域名，那么需要对sqlite数据库的数据进行修改。 ##问题 当迁移的机器域名变化时，需要怎么修改网站配置。 准备环境：安装sqlite3，sqlitebrowser 最重要的就是需要修改两个配置： WordPress地址（URL）—-对应wp_options的 home站点地址（URL）—-对应wp_options的 siteurl 123UPDATE wp_options SET option_value = replace( option_value, ‘http://www.old.com’, ‘http://www.new.com’ ) WHERE option_name = ‘home’ OR option_name = ‘siteurl’;UPDATE wp_posts SET post_content = replace( post_content, ‘http://www.old.com’, ‘http://www.new.com’ ) ;UPDATE wp_posts SET guid = replace( guid, ‘http://www.old.com’, ‘http://www.new.com’ ) ; 注意： 第一，参考文章“sqlite数据库不能修改” 第二，参考文章“wordpress登陆跳转卡住” 第三，sqlitebrowser在update之后，需要执行“write changes”按钮，才能把修改写入到数据库文件中。 参考文章： http://www.2zzt.com/jcandcj/5883.html http://jingyan.baidu.com/article/ff4116258f144012e48237a7.html","tags":[]},{"title":"wordpress登陆跳转卡住","date":"2017-05-07T22:30:48.000Z","path":"2017/05/07/linux/bugfix/wordpress_login_fail/","text":"作者： 耗子007 现象以www.example.com域名为例 1www.example.com/wp-login.php?redirect_to=www.example.com/wp-admin%2F&amp;reauth=1 用户名和密码都是正确的，在redirect的时候，卡住不动。 解决方法这是由于wp-admin文件夹的权限问题导致的，可以修改该文件夹的访问权限，“chmod -R 755 wp-admin” 参考文章：http://wordpress.stackexchange.com/questions/113161/wp-admin-url-doesnt-allow-to-login-and-redirects-to-same-page","tags":[]},{"title":"golang strings.Join一个字符串的情况","date":"2017-05-07T22:28:28.000Z","path":"2017/05/07/golang/golang_string_join_usage/","text":"作者： 耗子007 现象123rt := strings.Join([]string&#123;“help”&#125;, “-“)fmt.Println(rt)return 结果此时help后面不会加上“-”，只会打印一个“help”","tags":[]},{"title":"Git代理配置及常见错误解决办法","date":"2017-05-07T22:28:28.000Z","path":"2017/05/07/linux/bugfix/git_use_error_fix/","text":"作者： 耗子007 配置代理123git config –global http.proxy http://name:password@proxyhk.huawei.com:8080git config –global https.proxy http://name:password@proxyhk.huawei.com:8080 比如这种错误的时候fatal: unable to access ‘https://github.com/kubernetes/kubernetes.git/’: server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none 123git config –global http.sslverify false （解决证书验证问题）git config –global https.sslverify false 注：不过这样并没有解决你证书的问题，只是跳过了而已。 Ubuntu在clone大的项目异常可能会出下面的错误: 12error: gnutls_handshake() failed: A TLS packet with unexpected length was received. while accessing …fatal: HTTP request failed 这就需要你自己重新编译安装git了。 1234567sudo apt-get install build-essential fakeroot dpkg-dev libcurl4-openssl-devsudo apt-get build-dep gitmkdir ~/git-opensslcd ~/git-opensslapt-get source gitdpkg-source -x git_1.7.9.5-1.dsccd git-1.7.9.5 修改“debian/control”文件，把所有的“libcurl4-gnutls-dev” 替换成“libcurl4-openssl-dev” 1sudo dpkg-buildpackage -rfakeroot -b 安装对应的版本： 123i386: sudo dpkg -i ../git_1.7.9.5-1_i386.debx86_64: sudo dpkg -i ../git_1.7.9.5-1_amd64.deb 注：git版本号，注意修改为你下载的对应版本号 参考文章： http://askubuntu.com/questions/186847/error-gnutls-handshake-failed-when-connecting-to-https-servers/187199#187199","tags":[]},{"title":"Docker代理配置","date":"2017-05-07T22:18:28.000Z","path":"2017/05/07/docker/docker_set_proxy/","text":"作者： 耗子007 非systemd情况下直接修改/etc/default/docker文件就行（Ubuntu下service启动docker，属于非systemd模式） 12export http_proxy=xxxxxxexport https_proxy=xxxxxx systemd模式下12mkdir /etc/systemd/system/docker.service.dtouch /etc/systemd/system/docker.service.d/http-proxy.conf 添加 1[Service] Environment=”HTTP_PROXY=http://proxy.example.com:80/” 或者 1Environment=”HTTP_PROXY=http://proxy.example.com:80/” “NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com” 刷新配置：sudo systemctl daemon-reload 验证配置是否成功：systemctl show –property=Environment docker 重启docker服务：sudo systemctl restart docker 参考文章 https://docs.docker.com/engine/admin/systemd/ http://www.jianshu.com/p/2e0c9ed5433d","tags":[]},{"title":"获取qemu创建的虚拟机的IP地址","date":"2017-05-07T22:08:28.000Z","path":"2017/05/07/linux/tools/qemu_get_vm_ip/","text":"作者： 耗子007 先用virsh net-list获取虚拟机的网络列表1234[root@localhost vms]# virsh net-listName State Autostart Persistent———————————————————-default active yes yes 然后获取IP的分配列表123456[root@localhost vms]# virsh net-dhcp-leases defaultExpiry Time MAC address Protocol IP address Hostname Client ID or DUID——————————————————————————————————————-2016-09-22 21:08:03 52:54:00:00:00:12 ipv4 192.168.122.7/24 rtos –2016-09-22 21:08:23 52:54:00:00:00:42 ipv4 192.168.122.226/24 rtos –2016-09-22 21:08:35 52:54:00:00:00:62 ipv4 192.168.122.5/24 rtos – 获取虚拟机的列表[root@localhost vms]# virsh listId Name State—————————————————-12 main running13 slaver1 running14 slaver2 running 注：virsh net-dhcp-leases 网络名：会把该网络上分配出去的IP地址显示出来 获取制定虚拟机的IPvirsh edit vmID可以看到虚拟机的MAC地址，然后到第二步中找到对应的IP。 如果有更好的办法可以联系我：duguhaotian@gmail.com","tags":[]},{"title":"Centos7 qemu虚拟机安装","date":"2017-05-07T19:08:28.000Z","path":"2017/05/07/linux/tools/install_vm_on_centos7/","text":"作者： 耗子007 需要的材料qemu-kvm能运行的qemu虚拟机镜像文件（如果你的机器是远端服务器，没办法使用virt-view等图形界面的话）已有的qemu系统镜像安装了openssh-server端安装qemu相关软件 1yum install qemu-kvm qemu-img virt-manager libvirt libvirt-python libvirt-client virt-install virt-viewer 准备可用的qemu虚拟机镜像文件条件：有一台PC机器，安装好了qemu 新建磁盘文件1qemu-img create -f qcow2 /root/my.qcow2 20G 安装虚拟机1virt-install -r 1024 –accelerate -n test -f /root/my.qcow2 –cdrom mini.iso –graphics=vnc,listen=0.0.0.0 注：mini.iso是ubuntu的最小安装盘，你可以用其他的代替 图形界面正常的安装流程 然后进入虚拟机安装openssh-server端，打开root的ssh登录权限。 此时，我们安装的虚拟机系统的所有文件都在/root/my.qcow2里面。所以，我们把它拷贝到你的centos上面，然后可以直接用这个镜像文件创建虚拟机了。 启动虚拟机的xml配置文件示例把自己的配置写到test.xml文件，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;domain type=’kvm’&gt;&lt;name&gt;test&lt;/name&gt;&lt;memory unit=’MiB’&gt;1024&lt;/memory&gt;&lt;currentMemory unit=’MiB’&gt;1024&lt;/currentMemory&gt;&lt;vcpu placement=’static’&gt;1&lt;/vcpu&gt;&lt;os&gt;&lt;type arch=’x86_64′ machine=’pc’&gt;hvm&lt;/type&gt;&lt;boot dev=’cdrom’/&gt;&lt;boot dev=’hd’/&gt;&lt;/os&gt;&lt;features&gt;&lt;acpi/&gt;&lt;apic/&gt;&lt;pae/&gt;&lt;/features&gt;&lt;clock offset=’utc’/&gt;&lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt;&lt;on_reboot&gt;restart&lt;/on_reboot&gt;&lt;on_crash&gt;restart&lt;/on_crash&gt;&lt;devices&gt;&lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt;&lt;disk type=’file’ device=’disk’&gt;&lt;driver name=’qemu’ type=’qcow2’/&gt;&lt;source file=’/root/guest.qcow2’/&gt;&lt;target dev=’vda’ bus=’virtio’/&gt;&lt;/disk&gt;&lt;controller type=’usb’ index=’0′&gt;&lt;/controller&gt;&lt;interface type=’network’&gt;&lt;mac address=’52:54:00:00:00:12’/&gt;&lt;source network=’default’/&gt;&lt;model type=’virtio’/&gt;&lt;/interface&gt;&lt;serial type=’pty’&gt;&lt;target port=’0’/&gt;&lt;/serial&gt;&lt;console type=’pty’&gt;&lt;target type=’serial’ port=’0’/&gt;&lt;/console&gt;&lt;channel type=’spicevmc’&gt;&lt;target type=’virtio’ name=’com.redhat.spice.0’/&gt;&lt;/channel&gt;&lt;input type=’tablet’ bus=’usb’/&gt;&lt;input type=’mouse’ bus=’ps2’/&gt;&lt;input type=’keyboard’ bus=’ps2’/&gt;&lt;graphics type=’spice’ autoport=’yes’/&gt;&lt;sound model=’ich6′&gt;&lt;/sound&gt;&lt;video&gt;&lt;model type=’qxl’ vram=’9216′ heads=’1’/&gt;&lt;/video&gt;&lt;redirdev bus=’usb’ type=’spicevmc’&gt;&lt;/redirdev&gt;&lt;memballoon model=’virtio’&gt;&lt;/memballoon&gt;&lt;/devices&gt;&lt;/domain&gt; 注：/usr/libexec/qemu-kvm 其他系统的位置不一样（如，ubuntu是在/user/bin/qemu-system-x86_64） 然后直接运行virsh create test.xml，此时你就可以通过ssh root@ip到你的虚拟机上了。","tags":[]},{"title":"安装expect","date":"2017-05-07T19:07:28.000Z","path":"2017/05/07/linux/tools/install_expect/","text":"作者： 耗子007 安装TCL下载地址：http://www.tcl.tk/software/tcltk/download.html 目前最新版本: tcl8.5.19-src.tar.gz 1234567891011wget http://prdownloads.sourceforge.net/tcl/tcl8.5.19-src.tar.gztar zxf tcl8.5.19-src.tar.gzcd tcl8.5.19/unix/./configuremakemake install 安装expectexpect 官网：http://expect.sourceforge.net/ 12345678910111213wget http://nchc.dl.sourceforge.net/project/expect/Expect/5.45/expect5.45.tar.gztar zxf expect5.45.tar.gzcd expect5.45./configure –with-tcl=/usr/local/lib/ –with-tclinclude=../tcl8.5.19/generic/makemake installln -s /usr/local/bin/expect /usr/bin/expect","tags":[]},{"title":"Golang运行shell脚本","date":"2017-05-07T19:05:28.000Z","path":"2017/05/07/golang/golang_notes_run_shell_ingo/","text":"作者： 耗子007 示例以获取容器ID为例 1234567891011func GetContainerID() (string, error) &#123;cmd := exec.Command(“/bin/bash”, “-c”, “cat /proc/self/cgroup | grep docker | grep -o -E ‘[0-9a-f]&#123;64&#125;’| head -n 1”)var out bytes.Buffercmd.Stdout = &amp;outerr := cmd.Run()if err != nil &#123;return “”, err&#125;return out.String(), nil&#125; 注：cmd.Stdout=&amp;out把脚本执行结果重定向到指定的地方。 参考文章http://c2pblog.sinaapp.com/archives/219","tags":[]},{"title":"容器内获取容器的完整ID","date":"2017-05-07T13:31:28.000Z","path":"2017/05/07/docker/docker_tips_getfullcid_in_container/","text":"作者： 耗子007 可以通过进程自己的cgroup的信息获取，cgroup中包含了docker容器的完整ID。在容器中运行cat /proc/self/cgroup得到如下结果： 123456789101112root@60dc9bc55a76:/home# cat /proc/self/cgroup11:devices:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a10:cpu,cpuacct:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a9:blkio:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a8:cpuset:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a7:freezer:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a6:hugetlb:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a5:net_cls,net_prio:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a4:memory:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a3:pids:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a2:perf_event:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a1:name=systemd:/docker/60dc9bc55a76c81847d502d8ed432f03c6de131a85653c7a27dbe7db25b5945a 可以通过下面的命令，提前出来docker容器ID： 1cat /proc/self/cgroup | grep docker | grep -o -E ‘[0-9a-f]&#123;64&#125;’ | head -n 1 参考链接：https://github.com/docker/docker/issues/19698","tags":[]},{"title":"Namespace","date":"2017-05-07T13:29:26.000Z","path":"2017/05/07/linux/kernel/linux_kernel_namespace/","text":"作者： 耗子007 Linux支持如下的namespaces: 123456789Namespace Constant IsolatesCgroup CLONE_NEWCGROUP Cgroup root directoryIPC CLONE_NEWIPC System V IPC, POSIX message queuesNetwork CLONE_NEWNET Network devices, stacks, ports, etc.Mount CLONE_NEWNS Mount pointsPID CLONE_NEWPID Process IDsUser CLONE_NEWUSER User and group IDsUTS CLONE_NEWUTS Hostname and NIS domain name 读取软链接的namespace类型和inode值： 12$ readlink /proc/$$/ns/utsuts:[4026531838] 参考链接：http://man7.org/linux/man-pages/man7/namespaces.7.html","tags":[]},{"title":"基于centos搭建wordpress的docker镜像","date":"2017-05-07T13:02:26.000Z","path":"2017/05/07/docker/build_wordpress_docker_image/","text":"作者： 耗子007 自定义的Dockerfile1234567891011121314151617181920212223242526272829303132333435363738FROM centosENV http_proxy http://username:password@proxy:8080ENV https_proxy http://username:password@proxy:8080#RUN echo “http_proxy=http://username:password@proxy:8080” &gt;&gt; /etc/apt/apt.conf#RUN echo “https_proxy=http://username:password@proxy:8080” &gt;&gt; /etc/apt/apt.confRUN touch /etc/wgetrcRUN echo “http_proxy=http://username:password@proxy:8080” &gt;&gt; /etc/wgetrcRUN echo “https_proxy=http://username:password@proxy:8080” &gt;&gt; /etc/wgetrcRUN source /etc/wgetrcRUN yum -y updateRUN yum -y install httpd httpd-devel zip unzip tar wgetRUN yum -y install php php-xml php-pdo php-gd php-mbstring sqlite sqlite-develRUN wget –no-check-certificate https://wordpress.org/latest.tar.gz（中文版链接：https://cn.wordpress.org/wordpress-4.5.3-zh_CN.tar.gz）RUN wget –no-check-certificate https://downloads.wordpress.org/plugin/sqlite-integration.1.8.1.zipRUN tar xvfz ./latest.tar.gzRUN unzip ./sqlite-integration.1.8.1.zipRUN rm -f ./latest.tar.gzRUN rm -f ./sqlite-integration.1.8.1.zipRUN mv wordpress /var/lib/wordpressRUN chown -R apache.apache /var/lib/wordpressRUN mv /var/lib/wordpress/wp-config-sample.php /var/lib/wordpress/wp-config.phpRUN mv sqlite-integration /var/lib/wordpress/wp-content/plugins/RUN mv /var/lib/wordpress/wp-content/plugins/sqlite-integration/db.php \\/var/lib/wordpress/wp-content/RUN echo “yes n | cp -ripf /var/lib/wordpress/* /var/www/html/ &gt; /dev/null 2&gt;&amp;1” &gt;&gt; /root/.bash_profileVOLUME /var/www/htmlRUN systemctl enable httpdEXPOSE 80#docker run –privileged -itd -p 8080:80 -v /root/wordpress/public_html:/var/www/html wordpress_sqlite bash -l -c “/sbin/init” 然后构建docker镜像，执行命令：docker build –tag wordpress_sqlite . 现在新建wordpress的在host上的文件目录，如：/home/rtos/workspace/wordpress/public_html/ 启动wordpress服务，执行如下命令： docker run –privileged -itd -p 8080:80 -v /home/rtos/workspace/wordpress/public_html/:/var/www/html wordpress_sqlite bash -l -c “sbin/init” 等待几分钟，访问http://localhost:8080，或者http://ip:8080 注意： 我们的博客数据是放到SQLite数据库 （/var/www/html/wp-content/database/.ht.sqlite文件） 而网站的所有程序是放到(目录/var/www/html) 关于如何备份数据以及迁移博客，后续分析。","tags":[]},{"title":"Ubuntu搭载shadowsocks服务","date":"2017-05-07T13:02:26.000Z","path":"2017/05/07/linux/tools/shadowsocks_in_ubuntu/","text":"作者： 耗子007 安装python和ss123apt-get updateapt-get install python-pippip install shadowsocks 开启ss服务直接前台开启1ssserver -p 443 -k password -m aes-256-cfb 优点：可以看到连接输出日志缺点：端口ssh连接会导致服务中断，root权限启动 后台开启并使用其他权限启动1ssserver -p 443 -k password -m aes-256-cfb –user nobody -d start 配置文件设置服务配置文件格式: 123456789101112&#123;“server”:”0.0.0.0″,“port_password”:&#123;“8381”:”haozi001″,“8382”:”haozi001″,“8383”:”haozi001″&#125;,“local_address”: “127.0.0.1”,“local_port”:1080,“timeout”:600,“method”:”aes-256-cfb”&#125; 注意：如果是在google cloud platform上面设置，需要打开设置的端口号（如8381等） 优点:可以同时配置多个端口和密码，支持多用户 启动和停止命令： 12ssserver -c /etc/shadowsocks.json -d startssserver -c /etc/shadowsocks.json -d stop","tags":[]},{"title":"Shell逐行遍历文件","date":"2017-05-07T13:02:26.000Z","path":"2017/05/07/linux/shells/shell_learn_readfile_lines/","text":"作者： 耗子007 while readread命令接收标准输入，或其他文件描述符的输入，得到输入后，read命令将数据放入一个标准变量中． 利用read读取文件时，每次调用read命令都会读取文件中的”一行”文本． 当文件没有可读的行时，read命令将以非零状态退出． 123456789cat filename| while read linedoecho “$&#123;line&#125;”donewhile read linedoecho “$&#123;line&#125;”done &lt; filename for var in filefor var in file 表示变量var在file中循环取值．取值的分隔符由$IFS确定． 123456789for line in $(cat filename)doecho “File:$&#123;line&#125;”donefor line in `cat filename`doecho “$&#123;line&#125;”done 如果输入文本每行中没有空格，则line在输入文本中按换行符分隔符循环取值． 如果输入文本中包括空格或制表符，则不是换行读取，line在输入文本中按空格分隔符或制表符或换行符特环取值． 可以通过把IFS设置为换行符来达到逐行读取的功能． IFS的默认值为：空白(包括：空格，制表符，换行符)． 注意：如何设置IFS为换行符 12OLD_IFS=”$IFS”IFS=$’\\x0A’ awk工具变量1awk -f my.awk filename","tags":[]},{"title":"awk笔记","date":"2017-05-07T13:02:26.000Z","path":"2017/05/07/linux/shells/shell_learn_awk1/","text":"作者： 耗子007 awk文件格式1234567891011121314\\#!/bin/awk -f #注意头部BEGIN &#123;\\#定义初始化变量&#125;&#123;\\#处理逻辑&#125;END &#123;&#125; 使用方法1awk -f my.awk filename 语法split( String, A, [Ere] )： 将 String 参数指定的参数分割为数组元素 A[1], A[2], . . ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS 特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。 split函数：以Ere分隔String并动态生成一个数组A（获取数组长度的方法，参考注意事项）。 substr( String, M, [ N ] ) ：返回具有 N 参数指定的字符数量子串。子串从 String 参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N 参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。 函数substr用于截取部分字符串，注意index从1开始。 ````substr ( string, starting position, [ length of string ] )` 注意事项： length函数不能用于数组长度计算，可以通过for(k in arry) count++; $1,2,3变量如果是用于字符串用途，不能用双引号括起来；","tags":[]},{"title":"官方镜像安装wordpress","date":"2017-05-07T13:02:26.000Z","path":"2017/05/07/linux/tools/install_wordpress_docker_image/","text":"作者： 耗子007 拉取官方镜像12docker pull wordpress:latestdocker pull mysql:latest 启动mysql容器服务12345docker run –name mysqlwp -e MYSQL_ROOT_PASSWORD=dockerRootMySQL \\-e MYSQL_DATABASE=wordpress \\-e MYSQL_USER=wordpress \\-e MYSQL_PASSWORD=wordpresspwd \\-d mysql 启动wordpress容器服务12345docker run –name wordpress –link mysqlwp:mysql -p 8080:80 \\-e WORDPRESS_DB_NAME=wordpress \\-e WORDPRESS_DB_USER=wordpress \\-e WORDPRESS_DB_PASSWORD=wordpresspwd \\-d wordpress 注意：官方的安装方式，博客书籍到保存到MySQL数据库里，而我们的MySQL是放到容器里面了。怎么回去书籍，后续研究。 优点：构建方便、快捷 缺点：第一，两个容器大概需要800MB的存储空间；第二，需要启动二个容器","tags":[]},{"title":"docker命令分析--Seccomp特性","date":"2017-03-01T19:33:39.000Z","path":"2017/03/01/docker/docker_cmd_analyse3_1_2/","text":"作者： 耗子007 Secure computing mode (Seccomp)是Linux内核的特性。可以使用Seccomp来限制容器内的行为。该特性的有效基于： Docker编译时加上了seccomp 内核打开了CONFIG_SECCOMP配置 修改默认Seccomp配置文件默认的Seccomp配置文件禁止了44个系统调用。可以参考默认的配置文件，自定义然后在docker run的时候用–security-opt设置自定义的配置文件，例如： 1$ docker run --rm -it --security-opt seccomp=/path/to/seccomp/profile.json hello-world 默认的Seccomp配置文件是一个白名单，没有指定的则是被禁止的。下表给出一些被禁止的系统调用（不是全部），以及原因。 Syscall Description acct Accounting syscall which could let containers disable their own resource limits or process accounting. Also gated by CAP_SYS_PACCT. add_key Prevent containers from using the kernel keyring, which is not namespaced. adjtimex Similar to clock_settime and settimeofday, time/date is not namespaced. Also gated by CAP_SYS_TIME. bpf Deny loading potentially persistent bpf programs into kernel, already gated by CAP_SYS_ADMIN. clock_ adjtime Time/date is not namespaced. Also gated by CAP_SYS_TIME. clock_ settime Time/date is not namespaced. Also gated by CAP_SYS_TIME. clone Deny cloning new namespaces. Also gated by CAP_SYS_ADMIN for CLONE_* flags, except CLONE_USERNS. create_ module Deny manipulation and functions on kernel modules. Obsolete. Also gated by CAP_SYS_MODULE. delete_ module Deny manipulation and functions on kernel modules. Also gated by CAP_SYS_MODULE. finit_ module Deny manipulation and functions on kernel modules. Also gated by CAP_SYS_MODULE. get_kernel_syms Deny retrieval of exported kernel and module symbols. Obsolete. get_ mempolicy Syscall that modifies kernel memory and NUMA settings. Already gated by CAP_SYS_NICE. init_ module Deny manipulation and functions on kernel modules. Also gated by CAP_SYS_MODULE. ioperm Prevent containers from modifying kernel I/O privilege levels. Already gated by CAP_SYS_RAWIO. iopl Prevent containers from modifying kernel I/O privilege levels. Already gated by CAP_SYS_RAWIO. kcmp Restrict process inspection capabilities, already blocked by dropping CAP_PTRACE. kexec_file_load Sister syscall of kexec_load that does the same thing, slightly different arguments. Also gated by CAP_SYS_BOOT. kexec_ load Deny loading a new kernel for later execution. Also gated by CAP_SYS_BOOT. keyctl Prevent containers from using the kernel keyring, which is not namespaced. lookup_ dcookie Tracing/profiling syscall, which could leak a lot of information on the host. Also gated by CAP_SYS_ADMIN. mbind Syscall that modifies kernel memory and NUMA settings. Already gated by CAP_SYS_NICE. mount Deny mounting, already gated by CAP_SYS_ADMIN. move_pages Syscall that modifies kernel memory and NUMA settings. name_to_handle_at Sister syscall to open_by_handle_at. Already gated by CAP_SYS_NICE. nfsservctl Deny interaction with the kernel nfs daemon. Obsolete since Linux 3.1. open_by_handle_at Cause of an old container breakout. Also gated by CAP_DAC_READ_SEARCH. perf_event_open Tracing/profiling syscall, which could leak a lot of information on the host. personality Prevent container from enabling BSD emulation. Not inherently dangerous, but poorly tested, potential for a lot of kernel vulns. pivot_ root Deny pivot_root, should be privileged operation. process_vm_readv Restrict process inspection capabilities, already blocked by dropping CAP_PTRACE. process_vm_writev Restrict process inspection capabilities, already blocked by dropping CAP_PTRACE. ptrace Tracing/profiling syscall, which could leak a lot of information on the host. Already blocked by dropping CAP_PTRACE. query_module Deny manipulation and functions on kernel modules. Obsolete. quotactl Quota syscall which could let containers disable their own resource limits or process accounting. Also gated by CAP_SYS_ADMIN. reboot Don’t let containers reboot the host. Also gated by CAP_SYS_BOOT. request_key Prevent containers from using the kernel keyring, which is not namespaced. set_ mempolicy Syscall that modifies kernel memory and NUMA settings. Already gated by CAP_SYS_NICE. setns Deny associating a thread with a namespace. Also gated by CAP_SYS_ADMIN. settimeofday Time/date is not namespaced. Also gated by CAP_SYS_TIME. stime Time/date is not namespaced. Also gated by CAP_SYS_TIME. swapon Deny start/stop swapping to file/device. Also gated by CAP_SYS_ADMIN. swapoff Deny start/stop swapping to file/device. Also gated by CAP_SYS_ADMIN. sysfs Obsolete syscall. _sysctl Obsolete, replaced by /proc/sys. umount Should be a privileged operation. Also gated by CAP_SYS_ADMIN. umount2 Should be a privileged operation. Also gated by CAP_SYS_ADMIN. unshare Deny cloning new namespaces for processes. Also gated by CAP_SYS_ADMIN, with the exception of unshare –user. uselib Older syscall related to shared libraries, unused for a long time. userfaultfd Userspace page fault handling, largely needed for process migration. ustat Obsolete syscall. vm86 In kernel x86 real mode virtual machine. Also gated by CAP_SYS_ADMIN. vm86old In kernel x86 real mode virtual machine. Also gated by CAP_SYS_ADMIN. 禁用Seccomp12$ docker run --rm -it --security-opt seccomp=unconfined debian:jessie \\ unshare --map-root-user --user sh -c whoami","tags":[]},{"title":"docker命令分析--权限管理","date":"2017-03-01T19:33:39.000Z","path":"2017/03/01/docker/docker_cmd_analyse3_1_1/","text":"作者： 耗子007 所有命令均基于docker1.11版本 运行时特权和Linux能力run命令与特权相关的几个选项： –cap-add: Add Linux capabilities –cap-drop: Drop Linux capabilities –privileged=false: Give extended privileges to this container –device=[]: Allows you to run devices inside the container without the –privileged flag. 注：默认的容器都是unprivileged，因此很多系统调用、设备等特权相关的操作都是干不了的。而且1.10版本之后增加了seccomp安全控制， 可能导致容器有了权限，但是一些系统调用被安全策略禁止了。关于安全策略seccomp可以参考文档Docker安全策略 docker run –privileged启动的容器，具有访问host上所有设备的能力，当然需要同时设置AppArmor或者SELinux允许容器相同的权限。 –device可以指定一个或者多个设备在容器中能正常使用，默认情况，容器对这些设备具有read、write和mknod的权限，这些权限可以通过”:rwm”来修改。mknod可以参考这篇博客 示例如下： 12345678910111213$ docker run --device=/dev/sda:/dev/xvdc --rm -it ubuntu fdisk /dev/xvdcCommand (m for help): q$ docker run --device=/dev/sda:/dev/xvdc:r --rm -it ubuntu fdisk /dev/xvdcYou will not be able to write the partition table.Command (m for help): q$ docker run --device=/dev/sda:/dev/xvdc:w --rm -it ubuntu fdisk /dev/xvdc crash....$ docker run --device=/dev/sda:/dev/xvdc:m --rm -it ubuntu fdisk /dev/xvdcfdisk: unable to open /dev/xvdc: Operation not permitted 相对于privileged的暴力权限，cap-add和cap-drop对权限的控制更细腻。Docker目前支持的权限设置列表如下： Capability Key Capability Description SETPCAP Modify process capabilities. SYS_MODULE Load and unload kernel modules. SYS_RAWIO Perform I/O port operations (iopl(2) and ioperm(2)). SYS_PACCT Use acct(2), switch process accounting on or off. SYS_ADMIN Perform a range of system administration operations. SYS_NICE Raise process nice value (nice(2), setpriority(2)) and change the nice value for arbitrary processes. SYS_RESOURCE Override resource Limits. SYS_TIME Set system clock (settimeofday(2), stime(2), adjtimex(2)); set real-time (hardware) clock. SYS_TTY_CONFIG Use vhangup(2); employ various privileged ioctl(2) operations on virtual terminals. MKNOD Create special files using mknod(2). AUDIT_WRITE Write records to kernel auditing log. AUDIT_CONTROL Enable and disable kernel auditing; change auditing filter rules; retrieve auditing status and filtering rules. MAC_OVERRIDE Allow MAC configuration or state changes. Implemented for the Smack LSM. MAC_ADMIN Override Mandatory Access Control (MAC). Implemented for the Smack Linux Security Module (LSM). NET_ADMIN Perform various network-related operations. SYSLOG Perform privileged syslog(2) operations. CHOWN Make arbitrary changes to file UIDs and GIDs (see chown(2)). NET_RAW Use RAW and PACKET sockets. DAC_OVERRIDE Bypass file read, write, and execute permission checks. FOWNER Bypass permission checks on operations that normally require the file system UID of the process to match the UID of the file. DAC_READ_SEARCH Bypass file read permission checks and directory read and execute permission checks. FSETID Don’t clear set-user-ID and set-group-ID permission bits when a file is modified. KILL Bypass permission checks for sending signals. SETGID Make arbitrary manipulations of process GIDs and supplementary GID list. SETUID Make arbitrary manipulations of process UIDs. LINUX_ IMMUTABLE Set the FS_APPEND_FL and FS_IMMUTABLE_FL i-node flags. NET_BIND_SERVICE Bind a socket to internet domain privileged ports (port numbers less than 1024). NET_BROADCAST Make socket broadcasts, and listen to multicasts. IPC_LOCK Lock memory (mlock(2), mlockall(2), mmap(2), shmctl(2)). IPC_OWNER Bypass permission checks for operations on System V IPC objects. SYS_CHROOT Use chroot(2), change root directory. SYS_PTRACE Trace arbitrary processes using ptrace(2). SYS_ BOOT Use reboot(2) and kexec_load(2), reboot and load a new kernel for later execution. LEASE Establish leases on arbitrary files (see fcntl(2)). SETFCAP Set file capabilities. WAKE_ALARM Trigger something that will wake up the system. BLOCK_SUSPEND Employ features that can block system suspend. cap-add和cap-drop都支持ALL，表示加上或者去掉所有能力。例如，加上所有能力，但是去掉MKNOD： 1$ docker run --cap-add=ALL --cap-drop=MKNOD ...","tags":[]},{"title":"docker命令分析--run命令","date":"2017-03-01T15:03:19.000Z","path":"2017/03/01/docker/docker_cmd_analyse3_1/","text":"作者： 耗子007 所有命令均基于docker1.11版本 容器最常用，也最复杂的命令应该是run命令了，这篇文章主要对docker run进行简单的分析。 使用手册1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]Run a command in a new container -a, --attach=[] Attach to STDIN, STDOUT or STDERR --add-host=[] Add a custom host-to-IP mapping (host:ip) --blkio-weight=0 Block IO weight (relative weight) --blkio-weight-device=[] Block IO weight (relative device weight, format: `DEVICE_NAME:WEIGHT`) --cpu-shares=0 CPU shares (relative weight) --cap-add=[] Add Linux capabilities --cap-drop=[] Drop Linux capabilities --cgroup-parent=&quot;&quot; Optional parent cgroup for the container --cidfile=&quot;&quot; Write the container ID to the file --cpu-period=0 Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota=0 Limit CPU CFS (Completely Fair Scheduler) quota --cpuset-cpus=&quot;&quot; CPUs in which to allow execution (0-3, 0,1) --cpuset-mems=&quot;&quot; Memory nodes (MEMs) in which to allow execution (0-3, 0,1) -d, --detach Run container in background and print container ID --detach-keys Specify the escape key sequence used to detach a container --device=[] Add a host device to the container --device-read-bps=[] Limit read rate (bytes per second) from a device (e.g., --device-read-bps=/dev/sda:1mb) --device-read-iops=[] Limit read rate (IO per second) from a device (e.g., --device-read-iops=/dev/sda:1000) --device-write-bps=[] Limit write rate (bytes per second) to a device (e.g., --device-write-bps=/dev/sda:1mb) --device-write-iops=[] Limit write rate (IO per second) to a device (e.g., --device-write-bps=/dev/sda:1000) --disable-content-trust=true Skip image verification --dns=[] Set custom DNS servers --dns-opt=[] Set custom DNS options --dns-search=[] Set custom DNS search domains -e, --env=[] Set environment variables --entrypoint=&quot;&quot; Overwrite the default ENTRYPOINT of the image --env-file=[] Read in a file of environment variables --expose=[] Expose a port or a range of ports --group-add=[] Add additional groups to run as -h, --hostname=&quot;&quot; Container host name --help Print usage -i, --interactive Keep STDIN open even if not attached --ip=&quot;&quot; Container IPv4 address (e.g. 172.30.100.104) --ip6=&quot;&quot; Container IPv6 address (e.g. 2001:db8::33) --ipc=&quot;&quot; IPC namespace to use --isolation=&quot;&quot; Container isolation technology --kernel-memory=&quot;&quot; Kernel memory limit -l, --label=[] Set metadata on the container (e.g., --label=com.example.key=value) --label-file=[] Read in a file of labels (EOL delimited) --link=[] Add link to another container --log-driver=&quot;&quot; Logging driver for container --log-opt=[] Log driver specific options -m, --memory=&quot;&quot; Memory limit --mac-address=&quot;&quot; Container MAC address (e.g. 92:d0:c6:0a:29:33) --memory-reservation=&quot;&quot; Memory soft limit --memory-swap=&quot;&quot; A positive integer equal to memory plus swap. Specify -1 to enable unlimited swap. --memory-swappiness=&quot;&quot; Tune a container&apos;s memory swappiness behavior. Accepts an integer between 0 and 100. --name=&quot;&quot; Assign a name to the container --net=&quot;bridge&quot; Connect a container to a network &apos;bridge&apos;: create a network stack on the default Docker bridge &apos;none&apos;: no networking &apos;container:&lt;name|id&gt;&apos;: reuse another container&apos;s network stack &apos;host&apos;: use the Docker host network stack &apos;&lt;network-name&gt;|&lt;network-id&gt;&apos;: connect to a user-defined network --net-alias=[] Add network-scoped alias for the container --oom-kill-disable Whether to disable OOM Killer for the container or not --oom-score-adj=0 Tune the host&apos;s OOM preferences for containers (accepts -1000 to 1000) -P, --publish-all Publish all exposed ports to random ports -p, --publish=[] Publish a container&apos;s port(s) to the host --pid=&quot;&quot; PID namespace to use --pids-limit=-1 Tune container pids limit (set -1 for unlimited), kernel &gt;= 4.3 --privileged Give extended privileges to this container --read-only Mount the container&apos;s root filesystem as read only --restart=&quot;no&quot; Restart policy (no, on-failure[:max-retry], always, unless-stopped) --rm Automatically remove the container when it exits --shm-size=[] Size of `/dev/shm`. The format is `&lt;number&gt;&lt;unit&gt;`. `number` must be greater than `0`. Unit is optional and can be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`. --security-opt=[] Security Options --sig-proxy=true Proxy received signals to the process --stop-signal=&quot;SIGTERM&quot; Signal to stop a container -t, --tty Allocate a pseudo-TTY -u, --user=&quot;&quot; Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) --userns=&quot;&quot; Container user namespace &apos;host&apos;: Use the Docker host user namespace &apos;&apos;: Use the Docker daemon user namespace specified by `--userns-remap` option. --ulimit=[] Ulimit options --uts=&quot;&quot; UTS namespace to use -v, --volume=[host-src:]container-dest[:&lt;options&gt;] Bind mount a volume. The comma-delimited `options` are [rw|ro], [z|Z], [[r]shared|[r]slave|[r]private], and [nocopy]. The &apos;host-src&apos; is an absolute path or a name value. --volume-driver=&quot;&quot; Container&apos;s volume driver --volumes-from=[] Mount volumes from the specified container(s) -w, --workdir=&quot;&quot; Working directory inside the container 上面的手册可以使用“docker run –help”或者到Docker官网查看。run用于在新容器中执行一条命令，首先会创建一个新容器然后执行一条指令，其实这里包含了create、start以及exec命令的作用。基本用法是：“docker run [OPTIONS] IMAGE [COMMAND] [ARG…]”注： 可选选项OPTIONS：run具有丰富的选项，可以设置容器的一些特性 IMAGE：指定容器运行的基础镜像 可选命令COMMAND：容器运行时执行的命令 可选参数ARG：命令带的参数 基础用法指定容器名并分配伪终端123$ docker run --name hello -it ubunturoot@a37b3b659c24:/#root@a37b3b659c24:/# 创建一个名字为hello的容器，并且分配一个伪终端，-i链接到容器的STDIN。 获取容器ID(–cidfile)123456$ docker run --cidfile ./test.cid --name hello ubuntu$ cat test.cidb504823b5a2d281e0f8ee329e14a8052bbeb171f7e50720fe0dab98ebd75587fV2R1C00B003$ docker run --cidfile ./test.cid --name hello ubuntudocker: Container ID file found, make sure the other container isn&apos;t running or delete ./test.cid.See &apos;docker run --help&apos;. 通过–cidfile指定写入容器ID的文件路径，如果test.cid文件存在，命令会返回错误。 特权容器123$ docker run -t -i --rm ubuntu bashroot@bc338942ef20:/# mount -t tmpfs none /mntmount: permission denied 默认，大部分危险的内核能力是对容器关闭的，因此上面执行失败。关于具体权限分析，参考run的权限设置文章。 12345$ docker run -t -i --privileged ubuntu bashroot@50e3f57e16e6:/# mount -t tmpfs none /mntroot@50e3f57e16e6:/# df -hFilesystem Size Used Avail Use% Mounted onnone 1.9G 0 1.9G 0% /mnt –privileged选项会赋给容器所有的能力，此时的容器具有和host相同的能力，这种用法是很危险，不建议这么使用。细分权限，可以参考run的权限设置文章。 设置工作目录1234$ docker run --rm --name hello -it ubuntu pwd/$ docker run -w /test --rm --name hello -it ubuntu pwd/test 默认情况下，容器的工作目录是根目录，-w可以设置该目录，如果该目录不存在，docker会在容器中创建该目录。 挂载数据卷123456--volume=[host-src:]container-dest[:&lt;options&gt;] Bind mount a volume. The comma-delimited `options` are [rw|ro], [z|Z], [[r]shared|[r]slave|[r]private], and [nocopy]. The &apos;host-src&apos; is an absolute path or a name value. 可以把host上的文件或者目录透传到容器内指定路径，例如： 12$ docker run -v `pwd`:`pwd` -w `pwd` -i -t ubuntu pwd$ docker run -t -i -v /var/run/docker.sock:/var/run/docker.sock -v /path/to/static-docker-binary:/usr/bin/docker busybox sh 可以设置容器内对该数据卷的读写权限。 可以从另外的容器挂载数据卷： 1$ docker run --volumes-from 777f7dc92da7 --volumes-from ba8c0c54f0f2:ro -i -t ubuntu pwd 设置容器的元数据12$ docker run -l my-label --label com.example.foo=bar ubuntu bash$ docker run --label-file ./labels ubuntu bash 三种方式设置：-l、–label以及–label-file。label的格式为key=value，可以没有value，如果key相同，value不同，后面的会覆盖前面的value。 透传设备到容器1234$ docker run --device=/dev/sdc:/dev/xvdc --device=/dev/sdd --device=/dev/zero:/dev/nulo -i -t ubuntu ls -l /dev/&#123;xvdc,sdd,nulo&#125;brw-rw---- 1 root disk 8, 2 Feb 9 16:05 /dev/xvdcbrw-rw---- 1 root disk 8, 3 Feb 9 16:05 /dev/sddcrw-rw-rw- 1 root root 1, 5 Feb 9 16:05 /dev/nulo –device可以把host的设备透传到容器。 设置容器的ulimitulimit可以设置soft和hard限制，格式如：=[:]例如： 1234$ docker run --ulimit nofile=1024:1024 --rm ubuntu sh -c &quot;ulimit -n&quot;1024$ docker run --rm ubuntu sh -c &quot;ulimit -n&quot;1048576 注意： 如果没有指定hard limit，那么soft limit的值也会被设置给hard limit 如果没有设置ulimit，继承daemon设置的默认ulimit 退出自动清理容器默认情况下，容器退出后，容器的数据都是保存的。如果要删除退出不用的容器，需要手动用rm命令删除。有时候，可能容器退出就没有意义了，可以设置–rm，保证容器退出之后，会被自动清理掉。例如： 1docker run --rm ubuntu sh -c &quot;ulimit -n&quot; 注意：不能和-d一起使用","tags":[]},{"title":"docker命令分析--其他","date":"2017-02-28T21:40:23.000Z","path":"2017/02/28/docker/docker_cmd_analyse5/","text":"作者： 耗子007 所有命令均基于docker1.11版本 上面的分析基本包含了容器相关的大部分命令，剩余一些系统信息、容器底层信息、容器插件或者其他组件相关的命令。但是本章只关注系统信息和容器底层信息相关的命令，其他命令就不做介绍，后续有时间可能会补充。 获取Docker系统相关信息12345Usage: docker info [OPTIONS]Display system-wide information --help Print usage 例如： 12345678910111213141516171819202122232425262728293031323334353637383940414243$ docker -D infoContainers: 14 Running: 3 Paused: 1 Stopped: 10Images: 52Server Version: 1.9.0Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 545 Dirperm1 Supported: trueExecution Driver: native-0.2Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge null hostKernel Version: 3.19.0-22-genericOSType: linuxArchitecture: x86_64Operating System: Ubuntu 15.04CPUs: 24Total Memory: 62.86 GiBName: dockerID: I54V:OLXT:HVMM:TPKO:JPHQ:CQCD:JNLC:O3BZ:4ZVJ:43XJ:PFHZ:6N2SDocker Root Dir: /var/lib/dockerDebug mode (client): trueDebug mode (server): true File Descriptors: 59 Goroutines: 159 System Time: 2015-09-23T14:04:20.699842089+08:00 EventsListeners: 0 Init SHA1: Init Path: /usr/bin/docker Docker Root Dir: /var/lib/docker Http Proxy: http://test:test@localhost:8080 Https Proxy: https://test:test@localhost:8080WARNING: No swap limit supportUsername: svendowideitRegistry: [https://index.docker.io/v1/]Labels: storage=ssd 这些信息里面，一般比较关注的是Storage和Logging驱动、插件、Registry地址等。注：全局-D可以是docker命令输出调试信息，在发送问题报告的时候，最好带上-D。 容器或镜像的底层信息有时可能需要知道容器或者镜像的一些底层信息，可以使用inspect命令获取。 123456789Usage: docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...]Return low-level information on a container or image -f, --format=\"\" Format the output using the given go template --help Print usage --type=container|image Return JSON for_specified_type, permissible values are \"image\" or \"container\" -s, --size Display total file sizes if the type is container format命令默认会把结果以JSON格式输出。注意： 默认情况下，当容器名和镜像名相同时，format会输容器的结果 当时如果指定了–format，format会返回两个的格式化结果 关于–format选项可以参考Go语言的模板，这里只介绍简单的用法，例如获取容器的ID： 1docker inspect -f='&#123; &#123;.Id&#125; &#125;' haozi 获取Docker版本信息123456Usage: docker version [OPTIONS]Show the Docker version information. -f, --format=\"\" Format the output using the given go template --help Print usage version命令可以获取Docker版本相关信息，可以用–format来格式化输出，如方法前面。例如： 123456789101112131415161718$ docker versionClient: Version: 1.11.2 UnicornVersion: 1.11.2.11.ict API version: 1.23 Go version: go1.7.4 Git commit: 008dfcd Built: Tue Feb 7 10:58:04 2017 OS/Arch: linux/amd64Server: Version: 1.11.2 UnicornVersion: 1.11.2.11.ict API version: 1.23 Go version: go1.7.4 Git commit: 008dfcd Built: Tue Feb 7 10:58:04 2017 OS/Arch: linux/amd64 这里比较重要的信息是Docker、API、Go等的版本，例如，Client和Server的版本号不一致可能有各种问题。","tags":[]},{"title":"docker命令分析--维测相关","date":"2017-02-28T21:00:43.000Z","path":"2017/02/28/docker/docker_cmd_analyse4/","text":"作者： 耗子007 所有命令均基于docker1.11版本 这里主要分析容器维测相关的几个命令： stats：获取容器资源使用状态 top：容器内运行进程信息 容器资源状态1234567Usage: docker stats [OPTIONS] [CONTAINER...]Display a live stream of one or more containers’ resource usage statistics -a, --all Show all containers (default shows just running) --help Print usage --no-stream Disable streaming stats and only pull the first result stats命令会返回一个持续的容器资源统计数据流，可以通过指定一些容器ID或者name来限制检测的数量。注： 你可以指定一个停止的容器，但是不会返回任何数据。 更详细的统计数据可以通过/containers/(id)/stats API获取 例如，获取所有运行的容器资源数据： 12345$ docker statsCONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O1285939c1fd3 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KB9c76f7834ae2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 Bd1ea048f04e4 0.03% 4.583 MB / 64 MB 6.30% 2.854 KB / 648 B 27.7 MB / 0 B 容器内进程信息12345Usage: docker top [OPTIONS] CONTAINER [ps OPTIONS]Display the running processes of a container --help Print usage top命令会显示容器内运行进程的一些信息，例如： 123456# docker top hexoUID PID PPID C STIME TTY TIME CMDroot 3999 3983 0 Feb25 pts/24 00:00:00 /bin/sh -c hexo generate &amp;&amp; hexo serverroot 4097 3999 0 Feb25 pts/24 00:12:31 hexoroot 17660 17644 0 Feb27 pts/30 00:00:00 /bin/bashroot 28408 28392 0 Feb27 pts/31 00:00:00 /bin/bash 注意：top只会返回一次结果，和stats的结果不一样。","tags":[]},{"title":"docker命令分析--容器相关","date":"2017-02-27T19:20:23.000Z","path":"2017/02/27/docker/docker_cmd_analyse3/","text":"作者： 耗子007 所有命令均基于docker1.11版本 容器相关的命令，主要包括容器的管理、日志、信息查看以及内容操作。注：由于有些命令比较复杂，限于篇幅可能需要单独开一章，进行详细分析。 容器管理容器的管理涉及容器的整个生命周期：创建、启动、运行、挂起、唤醒、重启、停止、杀死以及删除。本文以容器的生命周期为主线一个个罗列相关命令。 容器的创建12345Usage: docker create [OPTIONS] IMAGE [COMMAND] [ARG...]Create a new container...... 注意：由于docker create的选项和docker run是一样的，因此这里不详细说明，等到docker run分析的时候，再详细分析。create用于创建一个新的容器，主要工作有： 在指定镜像之上，创建容器的可写层； 并且准备容器运行指定的命令 输出容器ID到STDOUT “docker create”和”docker run -d”是基本一样的，除了不启动容器外，当然，你可以在任何时候用docker start启动创建的容器。介绍几个简单的使用示例:创建并启动一个可交互的容器 1234$ docker create -t -i fedora bash6d8af538ec541dd581ebc2a24153a28329acb5268abe5ef868c1f1a261221752$ docker start -a -i 6d8af538ec5bash-4.2# 创建数据卷容器 这是由于v1.4.0后容器的数据卷是在create的阶段进行初始化的，因此create容器数据卷，然后直接在其他容器使用，如下： 123456$ docker create -v /data --name data ubuntu240633dfbb98128fa77473d3d9018f6123b99c454b3251427ae190a7d951ad57$ docker run --rm --volumes-from data ubuntu ls -la /datatotal 8drwxr-xr-x 2 root root 4096 Dec 5 04:10 .drwxr-xr-x 48 root root 4096 Dec 5 04:11 .. 更详细的分析参考docker run和Docker run refrence。 容器的启动12345678Usage: docker start [OPTIONS] CONTAINER [CONTAINER...]Start one or more containers -a, --attach Attach STDOUT/STDERR and forward signals --detach-keys Specify the escape key sequence used to detach a container --help Print usage -i, --interactive Attach container STDIN start命令用于启动一个或者多个容器。start命令的几个参数选项的含义和其他命令的含义是一致的： -a：链接到容器的STDOUT/STDERR，而且可以接收到容器的信号 –detach-keys：这个指定detach的快捷键 -i：表示连接到容器的STDIN，这样才能做一些输入操作，例如敲bash命令 注意：这里的-a只是能接收STDOUT/STDERR的数据，如果另外一个shell窗口用docker exec -it连到一个容器，exec里面对容器的操作不会反抗到start -a的窗口。 有点类似于-a是串口，而exec是ssh登录进去的情况。 容器的运行run命令可以用于直接运行容器，可以理解为run = create + start，由于这部分内容比较多，单独用一篇文章描述。 容器的挂起12345Usage: docker pause [OPTIONS] CONTAINER [CONTAINER...]Pause all processes within a container --help Print usage pause命令可以暂停一个容器内所有的进程。 容器的唤醒12345Usage: docker unpause [OPTIONS] CONTAINER [CONTAINER...]Unpause all processes within a container --help Print usage unpause命令与pause命令相对应，用于唤醒一个容器内所有的进程。 容器的重启123456Usage: docker restart [OPTIONS] CONTAINER [CONTAINER...]Restart a container --help Print usage -t, --time=10 Seconds to wait-for-stop before killing the container restart命令用于重启一个容器，可以用-t设置等待容器停止的时间，超时则杀死容器。 容器的停止1234567Usage: docker stop [OPTIONS] CONTAINER [CONTAINER...]Stop a container by sending SIGTERM and then SIGKILL after agrace period --help Print usage -t, --time=10 Seconds to wait-for-stop before killing it stop命令可以通过发送SIGTERM以及合理间隔后发送的SIGKILL来停止一个容器，-t选项和restart的用法一致。注：只有容器的主进程才会收到SIGTERM信号，并且在合理间隔之后收到SIGKILL信号。 容器的杀死123456Usage: docker kill [OPTIONS] CONTAINER [CONTAINER...]Kill a running container using SIGKILL or a specified signal --help Print usage -s, --signal=\"KILL\" Signal to send to the container kill命令通过SIGKILL或者其他指定信号来杀死一个运行中的容器，-s选项可以指定一个发送给容器的信号。和stop一样，主进程会收到信号。 注意：如果ENTRYPOINT和CMD是以shell格式运行的，那么他们是不会收到信号的。这是由于这种情况下bash才是主进程, 只有PID为1的进程能收到。关于ENTRYPOINT和CMD可以参考官方文档 容器的删除12345678Usage: docker rm [OPTIONS] CONTAINER [CONTAINER...]Remove one or more containers -f, --force Force the removal of a running container (uses SIGKILL) --help Print usage -l, --link Remove the specified link -v, --volumes Remove the volumes associated with the container rm可以删除一个或者多个容器。可以通过指定–force选项，通过发送SIGKILL信号强制删除一个运行的容器，例如：docker rm –force redis可以通过–link删除默认网桥上指定的link，删除所有的网络配置，例如：docker rm –link /webapp/redis注意：–link不能删除用户指定的网络，只能删除默认网桥上的link。可以通过–volumes删除容器关联的数据卷，这里需要注意下面的情况： 123$ docker create -v awesome:/foo -v /bar --name hello redishello$ docker rm -v hello 这里只会删除/bar数据卷，/foo数据卷不会被删除，是由于/foo关联到host的文件或者目录awesome。 删除所有停止的容器：docker rm $(docker ps -a -q) 容器的重命名12345Usage: docker rename [OPTIONS] OLD_NAME NEW_NAMERename a container --help Print usage rename命令可以用于重命名容器。注意：如果你启动的时候没有指定容器的名字，docker会生成一个，但是你也可以用容器的ID作为OLD_NAME来重命名该容器。例如：docker rename b8929ca5eda3 haozi 容器的更新update命令用于更新容器的一些配置，详细可以参考update命令分析 关于容器生命周期相关的命令，就结束了。下面看看其他和容器相关的一些常用的命令。 attach和exec命令首先，attach可以挂到一个运行的容器上，而exec可以在容器内执行指定的命令。 12345678Usage: docker attach [OPTIONS] CONTAINERAttach to a running container --detach-keys=\"&lt;sequence&gt;\" Set up escape key sequence --help Print usage --no-stdin Do not attach STDIN --sig-proxy=true Proxy all received signals to the process attach命令可以挂到一个运行中的容器上，然后你可以看到该容器正在输出的内容，或者以交互的方式控制它。 停止一个容器默认使用Ctrl-c，这个组合键会发送一个SIGKILL信号给容器。但是–sig-proxy=true被设置的话，Ctrl-c会发送SIGINT给容器。可以通过Ctrl+p，Ctrl+q端口连接并保持容器运行。 注意：通过attach连接到容器的stdio，Docker提供1MB的缓存接收应用的输出，如果buffer满了，会影响attach的输出速度。 然后，exec可以在运行的容器中运行一条命令。当容器运行的第一条命令不是bash或者没有指定-it的时候，用attach连到容器是不能做一些输入或者指令操作的。但是我们可以用exec在容器内运行bash或者其他指令来达到操作容器的目的。 1234567891011Usage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...]Run a command in a running container -d, --detach Detached mode: run command in the background --detach-keys Specify the escape key sequence used to detach a container --help Print usage -i, --interactive Keep STDIN open even if not attached --privileged Give extended Linux capabilities to the command -t, --tty Allocate a pseudo-TTY -u, --user= Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) 注：exec只有在容器的第一个进程在运行时，才能执行。如果容器是pause状态，exec会返回失败。各选项作用： –detach：后台执行命令 –detach-keys：指定断开连接的快捷键 –interactive：支持输入 –privileged：设置运行命令在特权模式下运行 –tty：分配一个伪终端 –user：设置执行命令用户名 容器的日志123456789Usage: docker logs [OPTIONS] CONTAINERFetch the logs of a container -f, --follow Follow log output --help Print usage --since=\"\" Show logs since timestamp -t, --timestamps Show timestamps --tail=\"all\" Number of lines to show from the end of the logs logs命令可以获取容器的日志信息。logs的日志信息保存位置取决于日志的驱动，默认容器日志的驱动为json，数据保存在/var/lib/docker/containers/container-ID/container-ID-json.log文件。日志驱动可以通过docker run和docker daemon的–log-driver选项设置。 logs命令的选项作用： –follow：命令可以持续获取容器的STDOUT和STDERR的信息。 –since：命令值显示指定时间戳之后的日志 –timestamps：命令在每条日志之前加上时间戳 –tail：命令只显示日志最后的指定行数","tags":[{"name":"docker","slug":"docker","permalink":"http://duguhaotian.github.io/tags/docker/"},{"name":"docker命令","slug":"docker命令","permalink":"http://duguhaotian.github.io/tags/docker命令/"}]},{"title":"markdown文件格式导致hexo generate失败","date":"2017-02-25T16:50:23.000Z","path":"2017/02/25/linux/bugfix/hexo_generate_err1/","text":"作者： 耗子007 错误日志12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152INFO Start processingFATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlTemplate render error: (unknown path) [Line 191, Column 51] unexpected token: . at Object.exports.prettifyError (/blog/node_modules/nunjucks/src/lib.js:34:15) at new_cls.render (/blog/node_modules/nunjucks/src/environment.js:469:27) at new_cls.renderString (/blog/node_modules/nunjucks/src/environment.js:327:21) at /blog/node_modules/hexo/lib/extend/tag.js:66:9 at Promise._execute (/blog/node_modules/bluebird/js/release/debuggability.js:299:9) at Promise._resolveFromExecutor (/blog/node_modules/bluebird/js/release/promise.js:481:18) at new Promise (/blog/node_modules/bluebird/js/release/promise.js:77:14) at Tag.render (/blog/node_modules/hexo/lib/extend/tag.js:64:10) at Object.tagFilter [as onRenderEnd] (/blog/node_modules/hexo/lib/hexo/post.js:253:16) at /blog/node_modules/hexo/lib/hexo/render.js:65:19 at tryCatcher (/blog/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/blog/node_modules/bluebird/js/release/promise.js:510:31) at Promise._settlePromise (/blog/node_modules/bluebird/js/release/promise.js:567:18) at Promise._settlePromise0 (/blog/node_modules/bluebird/js/release/promise.jsFROM node:612:10) at Promise._settlePromises (/blog/node_modules/bluebird/js/release/promise.js:691:18) at Async._drainQueue (/blog/node_modules/bluebird/js/release/async.js:138:16) at Async._drainQueues (/blog/node_modules/bluebird/js/release/async.js:148:10) at Immediate.Async.drainQueues (/blog/node_modules/bluebird/js/release/async.js:17:14) at runCallback (timers.js:649:20) at tryOnImmediate (timers.js:622:5) at processImmediate [as _immediateCallback] (timers.js:594:5)FATAL (unknown path) [Line 191, Column 51] unexpected token: .Template render error: (unknown path) [Line 191, Column 51] unexpected token: . at Object.exports.prettifyError (/blog/node_modules/nunjucks/src/lib.js:34:15) at new_cls.render (/blog/node_modules/nunjucks/src/environment.js:469:27) at new_cls.renderString (/blog/node_modules/nunjucks/src/environment.js:327:21) at /blog/node_modules/hexo/lib/extend/tag.js:66:9 at Promise._execute (/blog/node_modules/bluebird/js/release/debuggability.js:299:9) at Promise._resolveFromExecutor (/blog/node_modules/bluebird/js/release/promise.js:481:18) at new Promise (/blog/node_modules/bluebird/js/release/promise.js:77:14) at Tag.render (/blog/node_modules/hexo/lib/extend/tag.js:64:10) at Object.tagFilter [as onRenderEnd] (/blog/node_modules/hexo/lib/hexo/post.js:253:16) at /blog/node_modules/hexo/lib/hexo/render.js:65:19 at tryCatcher (/blog/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/blog/node_modules/bluebird/js/release/promise.js:510:31) at Promise._settlePromise (/blog/node_modules/bluebird/js/release/promise.js:567:18) at Promise._settlePromise0 (/blog/node_modules/bluebird/js/release/promise.js:612:10) at Promise._settlePromises (/blog/node_modules/bluebird/js/release/promise.js:691:18) at Async._drainQueue (/blog/node_modules/bluebird/js/release/async.js:138:16) at Async._drainQueues (/blog/node_modules/bluebird/js/release/async.js:148:10) at Immediate.Async.drainQueues (/blog/node_modules/bluebird/js/release/async.js:17:14) at runCallback (timers.js:649:20) at tryOnImmediate (timers.js:622:5) at processImmediate [as _immediateCallback] (timers.js:594:5) 解决方法由于markdown文件中包含了“{ { *** } }”（注意括号之间没有空格），可以在“{加一个空格{”。","tags":[]},{"title":"docker命令分析--镜像相关","date":"2017-02-23T16:50:23.000Z","path":"2017/02/23/docker/docker_cmd_analyse2/","text":"作者： 耗子007 所有命令均基于docker1.11版本 镜像相关的命令主要包括三类： 镜像registry相关命令 镜像构建相关命令 镜像操作相关命令 镜像registry操作在使用docker的过程中，可能需要从镜像registry获取镜像，或者把自己构建的镜像保存到registry。包括下面几个命令： 123456login Log in to a Docker registrylogout Log out from a Docker registrypull Pull an image or a repository from a registrypush Push an image or a repository to a registrysearch Search the Docker Hub for imagestag Tag an image into a repository login和logout这两个命令主要是用于登录和退出Docker registry的，比较简单，这里只给出基本用法。 login命令 12345678Usage: docker login [OPTIONS] [SERVER]Log in to a Docker registry server, if no server isspecified \"https://index.docker.io/v1/\" is the default. --help Print usage -p, --password=\"\" Password -u, --username=\"\" Username 如果没有指定服务器地址，默认服务器地址为：https://index.docker.io/v1/。服务器地址可以是自己搭建的本地仓库。 logout命令 123456Usage: docker logout [SERVER]Log out from a Docker registry, if no server isspecified \"https://index.docker.io/v1/\" is the default. --help Print usage pull、push和search pull命令：用于从registry下拉镜像或者 1234567Usage: docker pull [OPTIONS] NAME[:TAG] | [REGISTRY_HOST[:REGISTRY_PORT]/]NAME[:TAG]Pull an image or a repository from the registry -a, --all-tags Download all tagged images in the repository --disable-content-trust=true Skip image verification --help Print usage 注：如果是在内网，需要配置代理，可以参考上篇文章。 用pull下载单个镜像 1234#获取默认debian:latest$ docker pull debian#指定debian的tag$ docker pull debian:jessie 上面的pull镜像的方式，可以保证你获取的镜像永远是最新的版本的。但是，如果你想获取某个特定版本的，可以通过digest的方式获取。 123456789$ docker pull ubuntu:14.0414.04: Pulling from library/ubuntu5a132a7e7af1: Pull completefd2731e4c50c: Pull complete28a2f68d1120: Pull completea3ed95caeb02: Pull completeDigest: sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2Status: Downloaded newer image for ubuntu:14.04 上面的镜像会包含一个Digest信息：sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2为了获取固定版本的镜像，可以通过下面的方式： 1docker pull ubuntu@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2 从其他registry获取镜像或者仓库 1docker pull myregistry.local:5000/testing/test-image 注： docker pull默认从Docker hub上面下拉镜像。 myregistry是否是支持insecure方式，如果不支持可能需要一些配置才能pull成功 获取一个仓库的所有镜像 1$ docker pull --all-tags fedora push命令：往registry推送镜像或者仓库 123456Usage: docker push [OPTIONS] NAME[:TAG]Push an image or a repository to the registry --disable-content-trust=true Skip image signing --help Print usage 注： 默认推送到Docker hub，可以推送的自己构建的registry。 –disable-content-trust=true可以跳过镜像签名 search命令：在Docker hub搜索镜像 12345678Usage: docker search [OPTIONS] TERMSearch the Docker Hub for images --automated Only show automated builds --help Print usage --no-trunc Don't truncate output -s, --stars=0 Only displays with at least x stars 注意：search的说明是在Docker hub上搜索，其实也可以用来搜索自己搭建的registry，但是，如果用registry容器镜像搭建的registry是没有打开search模块的。 因此，search功能在这样的registry上面是不能工作的。 通过镜像名搜索 1$ docker search ubuntu 通过镜像名和stars次数搜索 12345$ docker search --stars=3 busyboxNAME DESCRIPTION STARS OFFICIAL AUTOMATEDbusybox Busybox base image. 325 [OK] progrium/busybox 50 [OK]radial/busyboxplus Full-chain, Internet enabled, busybox made... 8 [OK] 这里stars表示该镜像在Docker Hub上被人关注的次数。 查询自动构建的镜像 1234$ docker search --stars=3 --automated busyboxNAME DESCRIPTION STARS OFFICIAL AUTOMATEDprogrium/busybox 50 [OK]radial/busyboxplus Full-chain, Internet enabled, busybox made... 8 [OK] automated感觉用来标识非官方镜像 查询未截断描述的镜像 12345$ docker search --stars=3 --no-trunc busyboxNAME DESCRIPTION STARS OFFICIAL AUTOMATEDbusybox Busybox base image. 325 [OK] progrium/busybox 50 [OK]radial/busyboxplus Full-chain, Internet enabled, busybox made from scratch. Comes in git and cURL flavors. 8 [OK] tagtag命令用于修改镜像的仓库名和tag 12345Usage: docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]Tag an image into a repository --help Print usage 注：如果需要把镜像push到一个自定的registry，首先需要就是tag镜像到该registry的一个仓库（参考文章：搭建本地的Docker registry）。","tags":[]},{"title":"docker命令分析--镜像相关2","date":"2017-02-23T16:50:23.000Z","path":"2017/02/23/docker/docker_cmd_analyse2_2/","text":"作者： 耗子007 所有命令均基于docker1.11版本 镜像构建这部分主要包含，镜像制作相关的命令分析。镜像制作有三种情况： 从零开始，基于rootfs制作 基于已有镜像，用Dockerfile制作 保存运行容器为镜像 对应的三个命令如下： import 导入tar包内容，创建一个文件系统镜像 build 基于Dockerfile构建镜像 commit 把容器的修改制作为一个新的镜像 import命令123456789Usage: docker import file|URL|- [REPOSITORY[:TAG]]Create an empty filesystem image and import the contents of thetarball (.tar, .tar.gz, .tgz, .bzip, .tar.xz, .txz) into it, thenoptionally tag it. -c, --change=[] Apply specified Dockerfile instructions while importing the image --help Print usage -m, --message= Set commit message for imported image 注意：import是会先创建一个空的文件系统镜像，然后把tar包的内容导入。这和后面提到的load命令的操作是不一样的。 import支持三种读取文件方式： 直接指定本地路径，例如：docker import /path/to/exampleimage.tgz 指定远程URL，例如：docker import http://example.com/exampleimage.tgz 通过STDIN，分两种情况，一个是tar包文件，例如：cat exampleimage.tgz | docker import - exampleimagelocal:new ；一个是目录，例如：tar -c . | docker import - exampleimagedir import的-c选项在已创建的镜像上用Dockerfile的指令对镜像做修改，目前支持的指令有：CMD|ENTRYPOINT|ENV|EXPOSE|ONBUILD|USER|VOLUME|WORKDIR。例如，给新制作的镜像增加一个DEBUG的环境变量：tar -c . | docker import –change “ENV DEBUG true” - exampleimagedir build命令1234567891011121314151617181920212223242526Usage: docker build [OPTIONS] PATH | URL | -Build a new image from the source code at PATH --build-arg=[] Set build-time variables --cpu-shares CPU Shares (relative weight) --cgroup-parent=\"\" Optional parent cgroup for the container --cpu-period=0 Limit the CPU CFS (Completely Fair Scheduler) period --cpu-quota=0 Limit the CPU CFS (Completely Fair Scheduler) quota --cpuset-cpus=\"\" CPUs in which to allow execution, e.g. `0-3`, `0,1` --cpuset-mems=\"\" MEMs in which to allow execution, e.g. `0-3`, `0,1` --disable-content-trust=true Skip image verification -f, --file=\"\" Name of the Dockerfile (Default is 'PATH/Dockerfile') --force-rm Always remove intermediate containers --help Print usage --isolation=\"\" Container isolation technology --label=[] Set metadata for an image -m, --memory=\"\" Memory limit for all build containers --memory-swap=\"\" A positive integer equal to memory plus swap. Specify -1 to enable unlimited swap. --no-cache Do not use cache when building the image --pull Always attempt to pull a newer version of the image -q, --quiet Suppress the build output and print image ID on success --rm=true Remove intermediate containers after a successful build --shm-size=[] Size of `/dev/shm`. The format is `&lt;number&gt;&lt;unit&gt;`. `number` must be greater than `0`. Unit is optional and can be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes). If you omit the unit, the system uses bytes. If you omit the size entirely, the system uses `64m`. -t, --tag=[] Name and optionally a tag in the 'name:tag' format --ulimit=[] Ulimit options build是根据Dockerfile和上下文构建Docker镜像，这里的上下文是PATH或者URL所指目录的文件。Dockerfile获取方式也是三种： 直接指定本地路径，例如以当前目录的Dockerfile和文件上下文构建：docker build . 指定远程URL，例如从github下载：docker build github.com/creack/docker-firefox 通过STDIN，两种情况，一个是不包含上下文：docker build - &lt; Dockerfile；一个是带上下文docker build - &lt; context.tar.gz 关于build命令的选项，这里就描述几个常用的，其他的可以参考官方文档。 -t：用于指定构建的镜像的repository名和tag，值的格式为“name:tag”，例如：docker build -t vieux/apache:2.0 . 也可以给一个镜像指定多个tag，例如：docker build -t whenry/fedora-jboss:latest -t whenry/fedora-jboss:v2.1 .-f：指定Dockerfile文件路径，默认的Dockerfile名就是Dockerfile，build命令的上下文路径里面必须有Dockerfile文件， 但是可以通过-f来指定其他名字的Dockerfile文件，例如：docker build -f Dockerfile.debug .–build-arg：设置build过程中的参数，该参数的有效期为build过程，例如设置HTTP_PROXY环境变量：docker build –build-arg HTTP_PROXY=http://10.20.30.2:1234 . commit命令123456789Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]Create a new image from a container's changes -a, --author=\"\" Author (e.g., \"John Hannibal Smith &lt;hannibal@a-team.com&gt;\") -c, --change=[] Apply specified Dockerfile instructions while committing the image --help Print usage -m, --message=\"\" Commit message -p, --pause=true Pause container during commit commit以运行的容器构建Docker镜像，可以在命令最后面直接指定新构建的镜像repository和tag。commit命令可以方便的保存当前容器的状态到镜像中，然后可以方便的迁移到另外一台机器中继续运行，用于测试或者调试是很好的方法。不过，管理镜像还是用Dockerfile更合理。 commit命令的选项比较简单，主要包括： -a 设置镜像的作者 -c 和import命令一样 -m 设置commit的信息 -p 可以设置构建镜像过程中，是否停止容器中进程运行，默认情况下是停止容器中的进程。 镜像操作镜像操作主要是镜像的导入、导出、删除、查看镜像列表以及查看镜像的历史信息，对应命令如下： load/save import/export images rmi history 导入导出镜像的导入导出有两组命令，分别是import/export和load/save。 导入 import可以参考上文。load命令：只是从tar包或者STDIN中加载镜像。 1234567Usage: docker load [OPTIONS]Load an image from a tar archive or STDIN --help Print usage -i, --input=\"\" Read from a tar archive file, instead of STDIN. The tarball may be compressed with gzip, bzip, or xz -q, --quiet Suppress the load output. Without this option, a progress bar is displayed. import和load的区别在于： import会创建一个空的文件系统镜像，然后才会把tar包或者STDIN中的内容导入到空的镜像中。（会从零开始创建一个镜像） load只是把tar包或者STDIN中的镜像导入，这说明tar包或者STDIN中的输入本身就是一个镜像。（简单的导入已有镜像） 导出 export命令：导出容器的文件系统到tar文件。 123456Usage: docker export [OPTIONS] CONTAINERExport the contents of a container's filesystem as a tar archive --help Print usage -o, --output=\"\" Write to a file, instead of STDOUT 两种用法： docker export hexo &gt; myhexo.tar docker export –output=”myhexo.tar” hexo 注： export不导出数据卷的内容 save命令：把一个或者多个镜像导出到tar文件。 123456Usage: docker save [OPTIONS] IMAGE [IMAGE...]Save one or more images to a tar archive (streamed to STDOUT by default) --help Print usage -o, --output=\"\" Write to a file, instead of STDOUT 注：save会把所有父层以及name:tag导出，除非重名name:tag。几种用法： 使用标准输出导出一个镜像： docker save busybox &gt; busybox.tar 指定输出流导出一个镜像：docker save –output busybox.tar busybox 导出整个repository：docker save -o fedora-all.tar fedora export和save都是导出容器镜像，区别在： export是导出容器的文件系统 save是保存加载的容器镜像 查看镜像列表1234567891011Usage: docker images [OPTIONS] [REPOSITORY[:TAG]]List images -a, --all Show all images (default hides intermediate images) --digests Show digests -f, --filter=[] Filter output based on conditions provided --format Pretty-print images using a Go template --help Print usage --no-trunc Don't truncate output -q, --quiet Only show numeric IDs history用于列出镜像列表，主要用法如下： 默认显示顶层的镜像、它们的repository名、tag以及镜像大小（如果镜像ID一样而且有多个tag或者repository，则会列出多次）：docker images 以repository名列出镜像列表（repository名必须完全匹配）：docker images java 以repository名和tag列出镜像列表（必须完全匹配）：docker images java:8 显示镜像的完整ID：docker images –no-trunc 以摘要列出镜像列表（只有v2以上版本的镜像才有digest）：docker images –digests 以filter过滤条件列出镜像列表，目前支持两种，第一个，过滤untagged镜像docker images –filter “dangling=true”； 第二个，过滤label，格式为label (label= or label==)，示例如：docker images –filter “label=com.example.version” 单独描述一下format的用法，format是用来格式化输出的，使用Go语言模板实现，支持格式如下： Placeholder Description .ID Image ID .Repository Image repository .Tag Image tag .Digest Image digest .CreatedSince Elapsed time since the image was created. .CreatedAt Time when the image was created. .Size Image disk size. 例如只显示镜像的ID和repository名字：docker images –format “{ {.ID} }: { {.Repository} }” 删除镜像1234567Usage: docker rmi [OPTIONS] IMAGE [IMAGE...]Remove one or more images -f, --force Force removal of the image --help Print usage --no-prune Do not delete untagged parents 注意： 镜像的长ID、短ID、tag或者digest都可以用于删除它 如果一个镜像有多个tag引用它，删除这个镜像之前，必须先删除所有tag引用。 当使用tag删除一个镜像时，她的digest引用自动会被删除 指定-f和镜像的ID，rmi命令会自动untag和删除所有匹配的镜像 查看镜像的历史12345678Usage: docker history [OPTIONS] IMAGEShow the history of an image -H, --human=true Print sizes and dates in human readable format --help Print usage --no-trunc Don't truncate output -q, --quiet Only show numeric IDs history会列出镜像的build历史，例如： 12345678# docker history ubuntuIMAGE CREATED CREATED BY SIZE COMMENT104bec311bcd 10 weeks ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0 B&lt;missing&gt; 10 weeks ago /bin/sh -c mkdir -p /run/systemd &amp;&amp; echo 'doc 7 B&lt;missing&gt; 10 weeks ago /bin/sh -c sed -i 's/^#\\s*\\(deb.*universe\\)$/ 1.895 kB&lt;missing&gt; 10 weeks ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0 B&lt;missing&gt; 10 weeks ago /bin/sh -c set -xe &amp;&amp; echo '#!/bin/sh' &gt; /u 745 B&lt;missing&gt; 10 weeks ago /bin/sh -c #(nop) ADD file:7529d28035b43a2281 128.9 MB","tags":[]},{"title":"docker命令分析--简介","date":"2017-02-23T15:00:39.000Z","path":"2017/02/23/docker/docker_cmd_analyse/","text":"作者： 耗子007 所有命令均基于docker1.11版本 docker命令可以通过docker –help查看docker命令的所有功能描述。结果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# docker --helpUsage: docker [OPTIONS] COMMAND [arg...] docker daemon [ --help | ... ] docker [ --help | -v | --version ]A self-sufficient runtime for containers.Options: --config=~/.docker Location of client config files -D, --debug Enable debug mode -H, --host=[] Daemon socket(s) to connect to -h, --help Print usage -l, --log-level=info Set the logging level --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify Use TLS and verify the remote -v, --version Print version information and quitCommands: accel Manage docker accelerators attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on a container or image kill Kill a running container load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container network Manage Docker networks pause Pause all processes within a container port List port mappings or a specific mapping for the CONTAINER ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart a container rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop a running container tag Tag an image into a repository top Display the running processes of a container unpause Unpause all processes within a container update Update configuration of one or more containers version Show the Docker version information volume Manage Docker volumes wait Block until a container stops, then print its exit codeRun 'docker COMMAND --help' for more information on a command. 第一步，先介绍一下docker命令的基本格式和用法；然后，分析docker命令涉及的选项options、环境变量以及配置文件；而docker的子命令在后续的文章中详细描述。需要注意，三种配置优先级： 命令选项options优先于环境变量和配置文件 环境变量优先于配置文件 docker命令格式1234# docker --helpUsage: docker [OPTIONS] COMMAND [arg...] docker daemon [ --help | ... ] docker [ --help | -v | --version ] 命令选项12345678910111213Options: --config=~/.docker client配置文件的路径 -D, --debug 使能debug模式 -H, --host=[] docker daemon的socket文件路径 -h, --help 帮助手册 -l, --log-level=info 设置日志级别 --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify Use TLS and verify the remote -v, --version 打印版本信息 环境变量docker命令行直接支持如下环境变量： DOCKER_API_VERSION – docker的API版本(例如：1.23) DOCKER_CONFIG – client的配置文件路径 DOCKER_CERT_PATH – 证书的文件路径 DOCKER_DRIVER – 镜像驱动使用 DOCKER_HOST – docker daemon的socket文件路径 DOCKER_NOWARN_KERNEL_VERSION – 忽略Linux内核不适配Docker的警告 DOCKER_RAMDISK – If set this will disable ‘pivot_root’. DOCKER_TLS_VERIFY – 设置是否使用TLS并验证远端服务 DOCKER_CONTENT_TRUST – When set Docker uses notary to sign and verify images. Equates to –disable-content-trust=false for build, create, pull, push, run. DOCKER_CONTENT_TRUST_SERVER – The URL of the Notary server to use. This defaults to the same URL as the registry. DOCKER_TMPDIR – docker临时文件存放路径 由于Docker是用go开发的，所以Docker可以使用go runtime的所有环境变量，例如： HTTP_PROXY HTTPS_PROXY NO_PROXY 注：在给Docker配置代理的时候，如果docker是用systemd启动的话，直接配置全局代理可能无效。可以使用如下方式： 1234567891011 mkdir /etc/systemd/system/docker.service.d touch /etc/systemd/system/docker.service.d/http-proxy.conf添加 [Service] Environment=\"HTTP_PROXY=http://proxy.example.com:80/\" 或者 Environment=\"HTTP_PROXY=http://proxy.example.com:80/\" \"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\"刷新配置：sudo systemctl daemon-reload验证配置是否成功：systemctl show --property=Environment docker重启docker服务：sudo systemctl restart docker 配置文件除了，环境变量，Docker也支持通过配置文件的方式设置一些值。配置文件默认的位置是~/.docker/，可以通过两个方式修改： 设置环境变量DOCKER_CONFIG 设置docker命令选项–config 除了config.json，配置文件目录下面其他的文件最好不好修改。config.json的配置项对应环境变量和命令行的选项的功能。config.json包含很多配置项，这里只测试一下detachKeys：离开一个容器但是保持容器运行的快捷键，默认是ctrl+p,ctrl+q。这里把它修改为ctrl+e,e. 123456# cat testconfig/config.json&#123; \"detachKeys\": \"ctrl-e,e\"&#125;//加载配置文件# docker --config ~/testconfig/ attach a03840eb1632 这样ctrl+e,e就可以离开容器并保持容器继续运行了。 子命令后续的文章会把docker的子命令分为五类分析： 镜像相关 容器相关 维测相关 组件相关 其他","tags":[]},{"title":"docker插件简介","date":"2017-02-14T20:30:26.000Z","path":"2017/02/14/docker/docker_plugin/","text":"作者： 耗子007 docker engine管理plugin系统docker plugin系统支持安装、启动、停止和删除docker引擎使用的插件。当前该机制只支持volume驱动，后续会支持更多。 安装与使用plugin插件以容器镜像的方式发布，可以保存到Docker Hub或者私有registry。插件相关命令如下： 12docker plugin install //安装docker plugin ls //检查安装插件 该命令会从Docker Hub或者私有registry下拉插件，提示你需要的权限或者capabilities，并且使能插件。 安装sshfs插件示例如下： 12345678910111213$ docker plugin install vieux/sshfsPlugin \"vieux/sshfs\" is requesting the following privileges:- network: [host]- capabilities: [CAP_SYS_ADMIN]Do you grant the above permissions? [y/N] yvieux/sshfs$ docker plugin lsID NAME TAG DESCRIPTION ENABLED69553ca1d789 vieux/sshfs latest the `sshfs` plugin true 使用sshfs插件创建数据卷： 12345678910$ docker volume create -d vieux/sshfs -o sshcmd=&lt;user@host:path&gt; -o password=&lt;password&gt; sshvolumesshvolume$ docker volume lsDRIVER VOLUME NAMElocal 2d75de358a70ba469ac968ee852efd4234b9118b7722ee26a1c5a90dcaea6751local 842a765a9bb11e234642c933b3dfc702dee32b73e0cf7305239436a145b89017local 9d72c664cbd20512d4e3d5bb9b39ed11e4a632c386447461d48ed84731e44034local be9632386a2d396d438c9707e261f86fd9f5e72a7319417901d84041c8f14a4dlocal e1496dfe4fa27b39121e4383d1b16a0a7510f0de89f05b336aab3c0deb4dda0evieux/sshfs sshvolume 开发plugin","tags":[]},{"title":"容器内调用reboot函数失败","date":"2017-02-08T15:00:26.000Z","path":"2017/02/08/docker/container_reboot/","text":"作者： 耗子007 问题描述在容器里面调用reboot函数，函数传入LINUX_REBOOT_CMD_CAD_ON, LINUX_REBOOT_CMD_CAD_OFF这两个参数都返回失败。reboot return -1,errno is 22(EINVAL) 分析查看官方文档(http://man7.org/linux/man-pages/man2/reboot.2.html)： 12345678Behavior inside PID namespaces Since Linux 3.4, when reboot() is called from a PID namespace (see pid_namespaces(7)) other than the initial PID namespace, the effect of the call is to send a signal to the namespace \"init\" process. The LINUX_REBOOT_CMD_RESTART and LINUX_REBOOT_CMD_RESTART2 cmd values cause a SIGHUP signal to be sent. The LINUX_REBOOT_CMD_POWER_OFF and LINUX_REBOOT_CMD_HALT cmd values cause a SIGINT signal to be sent. For the other cmd values, -1 is returned and errno is set to EINVAL. 上面的意思大概是：在非initial PID namespace中，调用reboot，会给init进程发送信号，信号取决于cmd的值。 LINUX_REBOOT_CMD_RESTART 和 LINUX_REBOOT_CMD_RESTART2，会发送SIGHUP信号 LINUX_REBOOT_CMD_POWER_OFF 和 LINUX_REBOOT_CMD_HALT，发送SIGINT信号 其他的直接返回-1，errno为EINVAL 这里可以推出我们在容器中执行reboot，入参为LINUX_REBOOT_CMD_CAD_ON, LINUX_REBOOT_CMD_CAD_OFF时，会报错的原因。 查看reboot系统调用的源码验证一下官方文档，部分代码如下： 12345678910111213141516171819202122232425262728SYSCALL_DEFINE4(reboot, int, magic1, int, magic2, unsigned int, cmd, void __user *, arg)&#123; struct pid_namespace *pid_ns = task_active_pid_ns(current); char buffer[256]; int ret = 0; /* We only trust the superuser with rebooting the system. */ if (!ns_capable(pid_ns-&gt;user_ns, CAP_SYS_BOOT)) return -EPERM; /* For safety, we require \"magic\" arguments. */ if (magic1 != LINUX_REBOOT_MAGIC1 || (magic2 != LINUX_REBOOT_MAGIC2 &amp;&amp; magic2 != LINUX_REBOOT_MAGIC2A &amp;&amp; magic2 != LINUX_REBOOT_MAGIC2B &amp;&amp; magic2 != LINUX_REBOOT_MAGIC2C)) return -EINVAL; /* * If pid namespaces are enabled and the current task is in a child * pid_namespace, the command is handled by reboot_pid_ns() which will * call do_exit(). */ ret = reboot_pid_ns(pid_ns, cmd); if (ret) return ret; ... ... 关键是reboot_pid_ns函数，该函数代码如下： 12345678910111213141516171819202122232425262728int reboot_pid_ns(struct pid_namespace *pid_ns, int cmd)&#123; if (pid_ns == &amp;init_pid_ns) return 0; switch (cmd) &#123; case LINUX_REBOOT_CMD_RESTART2: case LINUX_REBOOT_CMD_RESTART: pid_ns-&gt;reboot = SIGHUP; break; case LINUX_REBOOT_CMD_POWER_OFF: case LINUX_REBOOT_CMD_HALT: pid_ns-&gt;reboot = SIGINT; break; default: return -EINVAL; &#125; read_lock(&amp;tasklist_lock); force_sig(SIGKILL, pid_ns-&gt;child_reaper); read_unlock(&amp;tasklist_lock); do_exit(0); /* Not reached */ return 0;&#125; 代码解析： 如果当前的namespace是init_pid_ns，就返回0 非init_pid_ns时，就如上面文档所述，非指定的cmd，就直接返回EINVAL","tags":[]},{"title":"Linux打开文件的上限分析","date":"2017-02-06T19:30:28.000Z","path":"2017/02/06/linux/kernel/linux_file_nr_max/","text":"作者： 耗子007 Linux打开文件的上限，主要受文件句柄上限和文件描述符上限的限制。 文件句柄： A file handle is a pointer to an actual data structure 文件描述符： A file descriptor is a just an abstract key for accessing the file 因此，文件句柄和文件描述符是不一样的。 相关函数简介函数getdtablesize，获取文件描述符表格的大小。 12345678getdtablesize() returns the maximum number of files a process canhave open, one more than the largest possible value for a filedescriptor.系统调用如下：SYSCALL_DEFINE0(getdtablesize)&#123; return sysctl_nr_open;&#125; 文件描述符上限相关文件描述符上限可以同ulimit进行设置，如下： 1ulimit -n 64000 获取当前文件描述符的上限，如下： 1234567891011121314151617181920# cat /proc/self/limitsLimit Soft Limit Hard Limit UnitsMax cpu time unlimited unlimited secondsMax file size unlimited unlimited bytesMax data size unlimited unlimited bytesMax stack size 8388608 unlimited bytesMax core file size unlimited unlimited bytesMax resident set unlimited unlimited bytesMax processes 1048576 1048576 processesMax open files 64000 64000 filesMax locked memory 65536 65536 bytesMax address space unlimited unlimited bytesMax file locks unlimited unlimited locksMax pending signals 10546 10546 signalsMax msgqueue size 819200 819200 bytesMax nice priority 0 0Max realtime priority 0 0Max realtime timeout unlimited unlimited us 如上所示，Max open files为我们设置的64000。 文件句柄相关系统使用的文件句柄的统计数据放在/proc/sys/fs/file-nr文件中，该文件包含三部分： 已分配的文件句柄数 分配但未使用的文件句柄数 最大的文件句柄数 例如： 12# cat /proc/sys/fs/file-nr896 0 267456 上述的数据，在内核中是保存在结构体files_stat_struct的变量files_stat中，该值在files_init函数中初始化。 123456789101112131415161718192021222324252627282930/* And dynamically-tunable limits and defaults: */struct files_stat_struct &#123; unsigned long nr_files; /* read only */ unsigned long nr_free_files; /* read only */ unsigned long max_files; /* tunable */&#125;;/* sysctl tunables... */struct files_stat_struct files_stat = &#123; .max_files = NR_FILE /* This constant is 8192 */&#125;;void __init files_init(unsigned long mempages)&#123; unsigned long n; filp_cachep = kmem_cache_create(\"filp\", sizeof(struct file), 0, SLAB_HWCACHE_ALIGN | SLAB_PANIC, NULL); /* * One file with associated inode and dcache is very roughly 1K. * Per default don't use more than 10% of our memory for files. */ n = (mempages * (PAGE_SIZE / 1024)) / 10; files_stat.max_files = max_t(unsigned long, n, NR_FILE); files_defer_init(); lg_lock_init(files_lglock); percpu_counter_init(&amp;nr_files, 0);&#125; 从函数files_init中可以知道，文件句柄的最大值等于NR_FILE或者10%的内存。因此，文件句柄的上限取决于系统的内存大小。 参考文章： [1] http://serverfault.com/questions/716578/default-value-of-proc-sys-fs-file-max[2] http://www.linuxvox.com/2015/12/what-are-file-max-and-file-nr-linux-kernel-parameters/","tags":[]},{"title":"Docker容器可视化","date":"2017-01-24T10:37:28.000Z","path":"2017/01/24/docker/docker_visual/","text":"作者： 耗子007 Google的cadvisor项目cadvisor用于分析运行容器的资源使用和利用率。cadvisor本身已经容器化，应该使用起来非常简单。cadvisor的项目地址：https://github.com/google/cadvisor下载cadvisor的镜像： 1docker pull google/cadvisor 启动cadvisor的容器服务： 123456789sudo docker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:rw \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --publish=8070:8080 \\ --detach=true \\ --name=cadvisor \\ google/cadvisor:latest 通过IP或者域名加端口号访问，就可以可视化的看到机器上运行的容器的资源使用情况了。 1http://&lt;hostname&gt;:&lt;port&gt;/","tags":[]},{"title":"Docker update命令分析","date":"2017-01-19T11:13:28.000Z","path":"2017/01/19/docker/docker_update/","text":"作者： 耗子007 update命令的主要作用：动态更新容器的配置。注意： 可以同时指定多个容器， 容器之间以空格间隔 对于–kernel-memory，只能对stopped容器进行更新。其它的配置支持running或stoped的容器。 然后，看看官方手册，docker update的用法如下： 1234567891011121314151617Usage: docker update [OPTIONS] CONTAINER [CONTAINER...]Update configuration of one or more containersOptions: --blkio-weight value Block IO (relative weight), between 10 and 1000 --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota -c, --cpu-shares int CPU shares (relative weight) --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --help Print usage --kernel-memory string Kernel memory limit -m, --memory string Memory limit --memory-reservation string Memory soft limit --memory-swap string Swap limit equal to memory plus swap: '-1' to enable unlimited swap --restart string Restart policy to apply when a container exits CPU相关参数cpu-shares参数：设置容器的CPU占用的相对权重，如果有两容器在一个核上面运行，一个cpu-shares设置为1024，一个设置为512，那么这两个占用CPU时间的比例为2/1。此功能和cpuset-cpus参数一起使用，结果比较容易呈现。启动三个容器，cpu-shares分别为1024，1024，和512，cpuset-cpus=1。启动脚本如下(cpurun.sh就是一个while(1))： 123docker run -td --cpu-shares=512 --cpuset-cpus=1 -v /workspace:/test ubuntu sh -c \"/test/cpurun.sh\"docker run -td --cpu-shares=1024 --cpuset-cpus=1 -v /workspace:/test ubuntu sh -c \"/test/cpurun.sh\"docker run -td --cpu-shares=1024 --cpuset-cpus=1 -v /workspace:/test ubuntu sh -c \"/test/cpurun.sh\" top查看三个进程的cpu占有率，结果如下： 12345 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND17970 root 20 0 3852 1764 1104 S 15.0 0.0 0:19.35 sh18172 root 20 0 3852 1764 1104 S 15.0 0.0 0:11.47 sh 850 root 20 0 223264 42416 13860 S 13.7 0.5 2:44.50 docker28127 root 20 0 3464 1408 1104 S 8.0 0.0 0:01.25 sh 结果很明显，cpu占比的比例接近2：2：1.","tags":[]},{"title":"从源码安装tmux","date":"2017-01-17T10:00:26.000Z","path":"2017/01/17/linux/tools/install_tmux/","text":"作者： 耗子007 安装libevent首先，需要到官网(http://libevent.org/)去下载最新的源码，安装流程如下： 123456wget --no-check-certificate https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gztar -zxf libevent-2.0.22-stable.tar.gzcd libevent-2.0.22-stable./configure -prefix=/usrmake -j4make install 安装ncursestmux依赖ncurses，因此需要先安装ncurses，同样通过源码安装，脚本如下： 123456wget http://invisible-island.net/datafiles/release/ncurses.tar.gztar -zxf ncurses.tar.gzcd ncurses-5.9/./configuremake -j4make install 安装tmux1234567$ apt-get install automake #依赖aclocal命令$ git clone https://github.com/tmux/tmux.git$ cd tmux$ sh autogen.sh$ ./configure -prefix=/usr #注意prefix，不然安装到/usr/local/bin目录，可能执行不了$ make$ make install tmux已经安装，成功了！！！","tags":[]},{"title":"Systemd自动Unmount机制分析","date":"2017-01-17T10:00:26.000Z","path":"2017/01/17/linux/mount_enumerate/","text":"作者： 耗子007 遇到过systemd会自动unmount一些目录，导致异常。那么systemd为什么会出现autounmount的情况呢？这里进行简单的分析一下。 注：该异常的systemd版本为systemd-219-19.el7.x86_64 异常必现的方式1234567[root@lin ~]# mount -t ramfs /dev/nonexistent /hello/kitty[root@lin ~]# echo $?0[root@lin ~]# mount | grep /hello/kitty[root@lin ~]# umount /hello/kittyumount: /hello/kitty: not mounted[root@lin ~]# rmdir /hello/kitty 这里的/dev/nonexistent表示该设备不存在，注意这里必现是/dev目录下的才能触发该异常。查看/var/log/message会发现日志如下： 123Jun 1 11:07:44 ws systemd: Unit hello-kitty.mount is bound to inactive unit dev-littlecat.device. Stopping, too.Jun 1 11:07:44 ws systemd: Unmounting /hello/kitty...Jun 1 11:07:44 ws systemd: Unmounted /hello/kitty. 参考文档： Bug 1226528 - unwanted automatic umount when device does not exist for nondev fs 对应PATCH 监听mountinfo监听mountinfo调用流程 123456src/core/main.c main --&gt; src/core/manager.c manager_startup --&gt; src/core/manager.c manager_enumerate --&gt; src/core/mount.c mount_enumerate --&gt; src/libsystemd/sd-event/sd-event.c sd_event_add_io --&gt; /src/libsystemd/sd-event/sd-event.c source_io_register 注：manager_enumerate会加载所有的units，执行enumerate操作，由于mount的unit对应的是mount_enumerate。因此，会调用mount_enumerate函数。 mount_enumerate中注册的调用如下： 1234567891011sd_event_add_io(m-&gt;event, &amp;m-&gt;mount_event_source, fileno(m-&gt;proc_self_mountinfo), EPOLLPRI, mount_dispatch_io, m);sd_event_add_io(m-&gt;event, &amp;m-&gt;mount_utab_event_source, m-&gt;utab_inotify_fd, EPOLLIN, mount_dispatch_io, m); 需要注意： fileno(m-proc_self_mountinfo)，这个就是获取文件“/proc/self/mountinfo”的句柄。 EPOLLPRI，是epoll机制使用的参数，表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来） mount_dispatch_io，表示接收到事件时，触发的回调处理函数。 m-&gt;utab_inotify_fd,对应于文件“/run/mount” EPOLLIN，是epoll机制使用的参数，表示有可读数据。 sd_event_add_io函数事件调用的是source_io_register函数进行注册，它基于epoll机制实现。 1234567//source_io_register函数实现 ...... if (s-&gt;io.registered) r = epoll_ctl(s-&gt;event-&gt;epoll_fd, EPOLL_CTL_MOD, s-&gt;io.fd, &amp;ev); else r = epoll_ctl(s-&gt;event-&gt;epoll_fd, EPOLL_CTL_ADD, s-&gt;io.fd, &amp;ev); ...... 如果event已经注册，这通过EPOLL_CTL_MOD入参，进行更新，否则增加该event的监听。 这一串的调用，其实就是注册监听文件“/proc/self/mountinfo”或者“/run/mount”，当该文件有数据可读时，会触发回调函数mount_dispatch_io。 回调函数mount_dispatch_io发现”/proc/self/mountinfo”有新的mount，添加mount unit的流程以及添加需要umount依赖的流程： 12345--&gt; src/core/mount.c mount_load_proc_self_mountinfo --&gt; src/core/mount.c mount_setup_unit --&gt; src/core/mount.c unit_new --&gt; src/core/mount.c should_umount --&gt; src/core/mount.c unit_add_dependency_by_name -- UNIT_CONFLICTS -- SPECIAL_UMOUNT_TARGET 发现设备状态变化，触发unmount的调用流程： 1234567--&gt; src/core/device.c device_found_node --&gt; src/core/device.c device_update_found_by_name --&gt; src/core/device.c device_update_found_one --&gt; src/core/device.c device_set_state --&gt; src/core/unit.c unit_notify --&gt; src/core/job.c job_finish_and_invalidate -- JOB_STOP -- UNIT_CONFLICTED_BY --&gt; src/core/job.c job_finish_and_invalidate 修复PATCH分析 PATCH的unmount标准：识别出非mounted对应的what，并且识别just_mounted和just_changed的what。用于触发umount流程时，判断需要umount那些mount。 未打该PATCH之前的标准：所有非mounted的而且what不为空的mount，都会触发unmount流程。 12345678910111213141516171819202122232425262728293031323334353637383940if (!mount-&gt;is_mounted) &#123; + /* A mount point is gone */+ mount-&gt;from_proc_self_mountinfo = false; switch (mount-&gt;state) &#123; @@ -1710,13 +1715,17 @@ static int mount_dispatch_io(sd_event_source *source, int fd, uint32_t revents, break; &#125; - if (mount-&gt;parameters_proc_self_mountinfo.what) - (void) device_found_node(m, mount-&gt;parameters_proc_self_mountinfo.what, false, DEVICE_FOUND_MOUNT, true); + /* Remember that this device might just have disappeared */ + if (mount-&gt;parameters_proc_self_mountinfo.what) &#123; + if (set_ensure_allocated(&amp;gone, &amp;string_hash_ops) &lt; 0 || + set_put(gone, mount-&gt;parameters_proc_self_mountinfo.what) &lt; 0) + log_oom(); /* we don&apos;t care too much about OOM here... */ + &#125; &#125; else if (mount-&gt;just_mounted || mount-&gt;just_changed) &#123; - /* New or changed mount entry */ + /* A mount point was added or changed */ switch (mount-&gt;state) &#123; @@ -1741,12 +1750,27 @@ static int mount_dispatch_io(sd_event_source *source, int fd, uint32_t revents, mount_set_state(mount, mount-&gt;state); break; &#125; + + if (mount-&gt;parameters_proc_self_mountinfo.what) &#123; + + if (set_ensure_allocated(&amp;around, &amp;string_hash_ops) &lt; 0 || + set_put(around, mount-&gt;parameters_proc_self_mountinfo.what) &lt; 0) + log_oom(); + &#125; &#125; 触发不在around中的device的Unmount流程： 1234567+ SET_FOREACH(what, gone, i) &#123;+ if (set_contains(around, what))+ continue;++ /* Let the device units know that the device is no longer mounted */+ (void) device_found_node(m, what, false, DEVICE_FOUND_MOUNT, true);+ &#125; 注：what其实就是device","tags":[]},{"title":"Python杂记","date":"2017-01-17T10:00:26.000Z","path":"2017/01/17/python/python_notes_1/","text":"作者： 耗子007 最近被python的条件坑了一波，在此小计一下。python的IF的条件判断和C是一致的，0表示False，非0表示True。这本没什么问题，坑爹的是，很多函数的成功返回0，而失败返回-1，这就很容易被坑了。先看看0和-1的情况： 1234567891011121314151617root@rtos:/home/work/rtos# pythonPython 2.7.6 (default, Oct 26 2016, 20:30:19)[GCC 4.8.4] on linux2Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; if 0:... print(\"0 is True\")... else:... print(\"0 is False\")...0 is False&gt;&gt;&gt; if -1:... print(\"-1 is True\")... else:... print(\"-1 is False\")...-1 is True 字符串的find函数，在查找失败的时候返回-1，成功时返回匹配的起始下标。当匹配的起始下标是0和查找失败的时候，在if判断时候需要注意了。 12345678910111213141516171819202122232425&gt;&gt;&gt; tmp = \"abcdefg\"&gt;&gt;&gt; a = \"abc\"&gt;&gt;&gt; b = \"bcd\"&gt;&gt;&gt; if tmp.find(a):... print(\"%s find in %s\" % (a, tmp))... else:... print(\"%s cannot find in %s\" % (a, tmp))...abc cannot find in abcdefg&gt;&gt;&gt; if tmp.find(b):... print(\"%s find in %s\" % (b, tmp))... else:... print(\"%s cannot find in %s\" % (b, tmp))...bcd find in abcdefg&gt;&gt;&gt; c = \"234\"&gt;&gt;&gt; if tmp.find(c):... print(\"%s find in %s\" % (c, tmp))... else:... print(\"%s cannot find in %s\" % (c, tmp))...234 find in abcdefg","tags":[]},{"title":"搭建本地的Docker registry","date":"2017-01-03T19:00:26.000Z","path":"2017/01/03/docker/create_local_registry/","text":"作者： 耗子007 搭建非安全RegistryDocker官方hub上面已提供容器化的Registry，可以通过docker run直接启动一个本地的Registry的服务。 12docker run -d -p 5000:5000 \\ --restart=always --name registry registry:2 上传镜像的方法： 123docker pull ubuntudocker tag ubuntu localhost:5000/ubuntudocker push localhost:5000/ubuntu 可以通过数据卷的方式，把上传的docker镜像保存到指定的host目录： 123docker run -d -p 5000:5000 --restart=always --name registry \\ -v /data:/var/lib/registry \\ registry:2 跨机器访问非安全Registry跨机器访问非安全的Registry，需要对机器的Docker daemon的启动参数进行设置，设置方法取决于docker daemon的启动方式。以Ubuntu为例： 修改/etc/default/docker文件 添加DOCKER_OPTS=”–insecure-registry myregistrydomain.com:5000”，以myregistrydomain.com为例，也可以是IP地址 重启Docker daemon服务 搭建安全Registry首先，需要对openssl的配置做一些修改： Ubuntu配置文件： /etc/ssl/openssl.cnf Redhat配置文件： /etc/pki/tls/openssl.cnf 注：在上面的配置文件的[ v3_ca ]标签下面加上subjectAltName=IP:192.168.1.181 &lt;192.168.1.181为当期机器的IP&gt;参考文章：http://dockone.io/article/684 可以通过openssl生成自己的证书和密钥，用来验证。生成证书的方法： 123mkdir -p /certs &amp;&amp; openssl req \\ -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key \\ -x509 -days 365 -out certs/domain.crt 关于openssl生成密钥的办法还有下面的： 1234567$ echo subjectAltName = DNS:$HOST,IP:10.10.10.20,IP:127.0.0.1 &gt; extfile.cnf$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\ -CAcreateserial -out server-cert.pem -extfile extfile.cnfSignature oksubject=/CN=your.host.comGetting CA Private KeyEnter pass phrase for ca-key.pem: 参考文档：https://docs.docker.com/engine/security/https/ 生成账号密码： 12mkdir auth docker run --entrypoint htpasswd registry:2 -Bbn testuser testpassword &gt; auth/htpasswd 用生成的证书和密钥启动Registry的服务： 123456docker run -d -p 5000:5000 --restart=always --name registry \\ -v `pwd`/auth:/auth -v `pwd`/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \\ registry:2 跨机器访问安全Registry把Registry机器上生成的证书文件domain.crt拷贝到指定目录（取决于系统类型）： Ubuntu /etc/docker/certs.d/myregistrydomain.com:5000/ca.crt Redhat系统 /etc/pki/ca-trust/source/anchors/myregistrydomain.com:5000.crt，并更新证书update-ca-trust 然后重新启动Docker daemon的服务。最后，可以push镜像了。 1234docker pull ubuntudocker tag ubuntu myregistrydomain.com:5000/ubuntudocker push myregistrydomain.com:5000/ubuntudocker pull myregistrydomain.com:5000/ubuntu","tags":[]},{"title":"Docker容器log功能分析","date":"2016-12-29T11:26:28.000Z","path":"2016/12/29/docker/docker_log/","text":"作者： 耗子007 日志驱动 Driver Description none Disables any logging for the container. docker logs won’t be available with this driver. json-file Default logging driver for Docker. Writes JSON messages to file. syslog Syslog logging driver for Docker. Writes log messages to syslog. journald Journald logging driver for Docker. Writes log messages to journald. gelf Graylog Extended Log Format logging driver for Docker. Writes log messages to a GELF endpoint like Graylog or Logstash. fluentd Fluentd logging driver for Docker. Writes log messages to fluentd (forward input). awslogs Amazon CloudWatch Logs logging driver for Docker. Writes log messages to Amazon CloudWatch Logs. splunk Splunk logging driver for Docker. Writes log messages to splunk using HTTP Event Collector. etwlogs ETW logging driver for Docker on Windows. Writes log messages as ETW events. gcplogs Google Cloud Logging driver for Docker. Writes log messages to Google Cloud Logging. 在daemon启动的时候可以配置日志驱动，命令如下： 1docker daemon --log-driver=json-file --log-opt=map[] 默认的驱动是json-file，可配置选项通过log-opt设置。log-opt可选项如下： 1234--log-opt max-size=[0-9+][k|m|g]--log-opt max-file=[0-9+]--log-opt labels=label1,label2--log-opt env=env1,env2 例如：–log-opt max-size=2m限定日志文件的大小为2MB–log-opt max-file=7限定日志文件最多7个当日志文件超过2MB是，会写到第二个日志文件，如果日志文件超过7个时，会覆盖之前的日志文件。 容器日志容器日志是容器在运行过程中产生的日志，默认会保存到/var/lib/docker/containers/CID/CID-json.log文件中。可以用下面命令读取易读的日志： 1$ docker logs CID 日志处理流程图如下： syslog驱动设置容器日志到单个日志文件syslog驱动时，默认容器的日志都是输出到/var/log/messages文件中的，当需要把容器日志单独保存时，可以通过一些小办法实现。步骤如下： 设置容器日志的facility为一个特定值保证其他应用不会使用，例如：local5 配置一下rsyslog.cfg就好了，把local5的日志指定到一个文件中，例如： 1local5.* /var/log/mydocker.log Daemon挂掉时容器日志处理流程当daemon挂掉时，容器的日志会缓存到上图的fifo中，fifo的默认大小是1M，可以通过如下命令获取： 1$ cat /proc/sys/fs/pipe-max-size","tags":[]},{"title":"Ubuntu 14.04安装golang和liteide","date":"2016-12-29T10:26:28.000Z","path":"2016/12/29/golang/install_golang_liteide/","text":"作者： 耗子007 安装liteide12345678910$ git clone https://github.com/visualfc/liteide.git$ sudo apt-get update$ sudo apt-get install qt4-dev-tools libqt4-dev libqt4-core libqt4-gui libqtwebkit-dev g++$ cd liteide/build$ ./update_pkg.sh$ QTDIR=/usr ./build_linux.sh## Run it: ##$ cd ~/liteide/build/liteide/bin$ ./liteide 安装golang1234wget https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gztar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gzvi $HOME/.profile &gt; export PATH=$PATH:/usr/local/go/bin","tags":[]},{"title":"kiwi分析","date":"2016-12-08T18:33:28.000Z","path":"2016/12/08/linux/tools/kiwi_analyse/","text":"作者： 耗子007 1. kiwi简介1.1 kiwi是什么kiwi用Perl编写的，用于制作linux镜像的命令行工具。支持制作多种格式的镜像： ISO Live CD/DVD PXEBoot Hard Disk USB Amazon EC2 (.ami) Docker Google Cloud Format (..gce) KVM/Qemu (.qcow2) Open Virtualization Format (.ovf, .ova) Vagrant (.vagrant VirtualBox (.vdi) Virtual Hard Disk (.vhd) VMware (.vmdk) XEN 1.2 kiwi工作流kiwi的工作流分为两个流程： 准备。创建root目录，用于保存新文件系统的内容；然后从软件源（可以是安装镜像或者在线的仓库）安装请求的软件包；然后创建镜像描述文件（config.xml）；最后可选的自定义配置。该流程会输出一个“unpacked root tree”。 制作。kiwi会自动使用上个流程的输出制作镜像，此流程没有交互，但是可以通过修改image.sh脚本，实现在制作镜像过程中执行用户定义动作。 1.3 kiwi使用方法准备流程：kiwi –prepare制作流程：kiwi –create 2 kiwi的基本流程kiwi制作镜像的流程是自动的，制作需要的必要信息主要来自config.xml的配置文件。此外，kiwi可以通过config.sh和images.sh实现可选的自定义功能。 2.1 制作镜像kiwi制作镜像分为两步。第一步，prepare操作，使用config.xml配置文件生成“unpacked image tree”。第二步，create操作，基于第一步生成的“unpacked image”和config.xml配置文件提供的信息创建一个“packed image”（就是镜像）。 注： (1) Unpacked Image Encapsulated system reachable via chroot (2) Packed Image Encapsulated system reachable via kernel file system/extension drivers such as loopback mounts, etc. 2.1.1 Prepare操作只有prepare操作成功，才能进行下一步的create操作。prepare操作，kiwi会创建一个unpacked image（也就是root tree）。这个root tree是通过–root参数或者config.xml的defaultroot元素指定的。该目录会在create操作中用于安装软件。软件管理工具是通过config.xml的packagemanager元素指定的，kiwi目前支持的软件管理工具有：smart、zypper（默认选项）、yum和apt。Prepare操作主要包括以下步骤： 创建目标root目录。如果目标root目录存在，kiwi会退出并报错。可以使用–force-new-root参数，强制创建，如果指定目录存在，kiwi会先删除，然后重新创建。 安装软件包。把配置文件的bootstrap部分指定的软件安装到root目录。filesystem和glibc-locale（euler没指定此包）包是构建引导环境必需的软件。这两个包的依赖链足以在引导环境中填充所有必需的软件，以支持将软件包安装到新root目录中。软件包管理可能安装了一些不需要的软件包，可以通过”package_to_be_deleted“来删除多余的软件包。 应用overlay目录。软件包安装完成后，KIWI将名为root的overlay目录中存在的所有文件和目录拷贝到目标root tree。已经存在于目标root tree中的文件将被覆盖，其他将被添加。 这允许您覆盖在安装阶段期间软件包安装的任何文件。 安装archives。在上一步完成之后，把config.xml的archive元素指定的任何archive（可以使任何文件，以tar包形式保存），解开到目标root tree。可能覆盖掉已有的文件。 运行用户定义的脚本config.sh。prepare操作的最后，执行config.sh脚本，运行在root tree的顶层。该脚本的主要功能是完成系统配置，例如启动一些服务。更详细使用可参考 config.sh 管理新的root tree。你可以通过chroot操作新的root tree，此文件系统与常用的区别在于多一个image目录，用于保存kiwi在create步骤需要用到的信息，例如，config.xml配置文件的副本。 2.1.2 Create操作Prepare操作的成功时Create操作的前提。保证unpacked root tree是完整的和一致的。create操作会创建一个packed image。利用unpacked root tree能够创建多种类型image，例如，OEM image或者虚拟机的images。Create操作主要执行以下步骤： 运行用户自定义脚本images.sh。如果images.sh存在，首先在root tree的顶层执行此脚本。该脚本主要作用是删除最终镜像不需要的文件。更详细使用方法可参考 images.sh 创建请求类型镜像。创建config.xml的type元素指定的image类型，配置文件必须包含至少一个type元素。下图显示当前支持的镜像类型。","tags":[]},{"title":"基于hexo和docker搭建静态网站环境","date":"2016-12-07T17:26:28.000Z","path":"2016/12/07/docker/docker_hexo/","text":"作者： 耗子007 通过把hexo安装到docker容器中，然后在容器中启动hexo的服务。 构建hexo的docker镜像基于node的docker镜像制作我们的hexo镜像，主要做了如下几件事： 配置代理（内网需要） 添加hexo工作目录 安装全局hexo 初始化hexo工作目录 暴露hexo服务的端口 在启动时，生成静态页面以及启动hexo服务 Dockerfile如下所示： FROM node MAINTAINER Haozi007 ENV http_proxy http://name:password@proxy:8080 ENV https_proxy http://name:password@proxy:8080 # Create hexo work dir WORKDIR /blog RUN npm install -g hexo-cli RUN hexo init /blog EXPOSE 4000 CMD hexo generate && hexo server 制作docker镜像 docker build -t haozi/hexo . 启动hexo服务可以通过docker的-v方法，把我们的markdown文档指定到容器中hexo的工作目录的source/_posts目录中，这样当容器启动时，会自动生成对应的静态页面。启动容器的命令如下： docker run --name hexo -itd -p 8088:4000 \\ -v /home/rtos/learning/workNotes/blogs:/blog/source/_posts \\ haozi/hexo 注： -p把容器的4000端口映射到host的8088端口，这样访问host的8088端口，就可以访问我们的hexo网站了。 -v把markdown写的文档，映射到hexo的工作目录下的_posts目录，这样我们可以方便的更新文档 网站维护可以把我们的所有markdown文档传到github或者其它内源保存。每次更新文档的时候，有两种方法可以更新我们的hexo静态网站。 只需要重启我们的hexo容器 执行docker exec -it hexo /bin/bash进入容器，然后到/blog目录，执行hexo generate就可以了 前者需要重启容器，导致网站服务中断，后者比较麻烦，但是网站服务不好中断。","tags":[]}]